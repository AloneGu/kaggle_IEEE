{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Samsung-Galaxy-Note3': [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], 'LG-Nexus-5x': [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], 'iPhone-6': [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], 'Sony-NEX-7': [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'Samsung-Galaxy-S4': [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], 'Motorola-X': [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], 'iPhone-4s': [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], 'HTC-1-M7': [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], 'Motorola-Droid-Maxx': [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], 'Motorola-Nexus-6': [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]}\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import skimage\n",
    "import skimage.io\n",
    "import scipy.misc\n",
    "import imageio\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "\n",
    "list_classes = [\n",
    " 'Sony-NEX-7',\n",
    " 'Motorola-X',\n",
    " 'HTC-1-M7',\n",
    " 'Samsung-Galaxy-Note3',\n",
    " 'Motorola-Droid-Maxx',\n",
    " 'iPhone-4s',\n",
    " 'iPhone-6',\n",
    " 'LG-Nexus-5x',\n",
    " 'Samsung-Galaxy-S4',\n",
    " 'Motorola-Nexus-6']\n",
    "\n",
    "list_dict = {}\n",
    "for i in range(10):\n",
    "    key = list_classes[i]\n",
    "    v = [0,0,0,0,0,0,0,0,0,0]\n",
    "    v[i] = 1\n",
    "    list_dict[key] = v\n",
    "print(list_dict)\n",
    "\n",
    "train_dir = '../input/crop_train'\n",
    "test_dir = '../input/test'\n",
    "test_files = sorted(glob.glob(test_dir+'/*'))\n",
    "train_files = sorted(glob.glob(train_dir+'/*/*'))\n",
    "train_data_cnt = len(train_files)\n",
    "from sklearn.utils import shuffle\n",
    "train_files = shuffle(train_files,random_state=42)\n",
    "train_cnt = int(train_data_cnt * 0.8)\n",
    "valid_cnt = train_data_cnt - train_cnt\n",
    "BATCH_SIZE = 13\n",
    "CROP_LEN = 224\n",
    "\n",
    "def random_crop(im_array):\n",
    "    # crop\n",
    "    x_range = im_array.shape[0] - CROP_LEN\n",
    "    y_range = im_array.shape[1] - CROP_LEN\n",
    "    # print(x_range,y_range)\n",
    "    a = np.random.randint(x_range)\n",
    "    b = a + CROP_LEN\n",
    "    c = np.random.randint(y_range)\n",
    "    d = c + CROP_LEN\n",
    "    new_im_array = im_array[a:b,c:d,:]\n",
    "    return new_im_array\n",
    "\n",
    "def center_crop(im_array):\n",
    "    center_x = im_array.shape[0] // 2\n",
    "    center_y = im_array.shape[1] // 2\n",
    "    half_crop = CROP_LEN // 2\n",
    "    a = center_x - half_crop\n",
    "    b = a + CROP_LEN\n",
    "    c = center_y - half_crop\n",
    "    d = c + CROP_LEN\n",
    "    new_im_array = im_array[a:b,c:d,:]\n",
    "    return new_im_array\n",
    "    \n",
    "\n",
    "def get_img(img_path, train_flag = True):\n",
    "    # read img\n",
    "    im_array = np.array(Image.open((img_path)), dtype=\"uint8\")\n",
    "    \n",
    "    # train or valid\n",
    "    if train_flag is True:\n",
    "        final_img = random_crop(im_array)\n",
    "    else:\n",
    "        final_img = center_crop(im_array)\n",
    "    \n",
    "    final_img = final_img/127.5\n",
    "    final_img = final_img - 1.0\n",
    "    return final_img\n",
    "\n",
    "# 读取测试数据中间 224\n",
    "def get_test_img(img_path):\n",
    "    # read img\n",
    "    im_array = np.array(Image.open((img_path)), dtype=\"uint8\")\n",
    "    final_img = center_crop(im_array)\n",
    "    final_img = final_img/127.5\n",
    "    final_img = final_img - 1.0\n",
    "    return final_img\n",
    "\n",
    "def get_y(img_path):\n",
    "    n = img_path.split('/')[-2]\n",
    "    return list_dict[n]\n",
    "\n",
    "def data_gen(file_list, batch_size=BATCH_SIZE, train_flag = True):\n",
    "    curr_idx = 0\n",
    "    data_cnt = len(file_list)\n",
    "    while True:\n",
    "        if curr_idx + batch_size > data_cnt:\n",
    "            start_idx = data_cnt-batch_size\n",
    "            end_idx = data_cnt\n",
    "            curr_idx = 0\n",
    "        else:\n",
    "            start_idx = curr_idx\n",
    "            end_idx = curr_idx + batch_size\n",
    "            curr_idx += batch_size\n",
    "        curr_fl = file_list[start_idx:end_idx]\n",
    "        curr_x = [get_img(p,train_flag) for p in curr_fl]\n",
    "        curr_x = np.array(curr_x,dtype='float32')\n",
    "        curr_y = np.array([get_y(p) for p in curr_fl])\n",
    "        yield curr_x,curr_y\n",
    "\n",
    "train_gen = data_gen(train_files[:train_cnt], BATCH_SIZE, True)\n",
    "valid_gen = data_gen(train_files[train_cnt:], BATCH_SIZE, False)\n",
    "import math\n",
    "train_step = math.ceil(train_cnt*0.5/BATCH_SIZE)\n",
    "valid_step = math.ceil(valid_cnt/BATCH_SIZE)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# def model\n",
    "from keras.models import Sequential,load_model,Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Lambda, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint,ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load best_resnet_crop.h5\n"
     ]
    }
   ],
   "source": [
    "model_p = 'best_resnet_crop.h5'\n",
    "\n",
    "if os.path.exists(model_p):\n",
    "    model = load_model(model_p)\n",
    "    #K.set_value(model.optimizer.lr, 0.0001)\n",
    "    print('load',model_p)\n",
    "else:\n",
    "    from keras.applications.resnet50 import ResNet50\n",
    "    base_model = ResNet50(input_shape=(CROP_LEN,CROP_LEN,3),include_top=False,weights=None,pooling='max')\n",
    "    x = base_model.output\n",
    "    x = Dense(256,activation='relu')(x)\n",
    "    pred = Dense(10,activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.input,outputs=pred)\n",
    "    print('get model')\n",
    "    print(model.summary())\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(0.0001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "1353/1354 [============================>.] - ETA: 0s - loss: 0.1373 - acc: 0.9530Epoch 00001: val_acc improved from -inf to 0.87695, saving model to best_resnet_crop.h5\n",
      "1354/1354 [==============================] - 893s 660ms/step - loss: 0.1372 - acc: 0.9531 - val_loss: 0.4354 - val_acc: 0.8769\n",
      "Epoch 2/60\n",
      "1353/1354 [============================>.] - ETA: 0s - loss: 0.1498 - acc: 0.9498Epoch 00002: val_acc did not improve\n",
      "1354/1354 [==============================] - 882s 651ms/step - loss: 0.1497 - acc: 0.9498 - val_loss: 0.4378 - val_acc: 0.8752\n",
      "Epoch 3/60\n",
      "1353/1354 [============================>.] - ETA: 0s - loss: 0.1373 - acc: 0.9538Epoch 00003: val_acc improved from 0.87695 to 0.89149, saving model to best_resnet_crop.h5\n",
      "1354/1354 [==============================] - 883s 652ms/step - loss: 0.1372 - acc: 0.9538 - val_loss: 0.3756 - val_acc: 0.8915\n",
      "Epoch 4/60\n",
      "1353/1354 [============================>.] - ETA: 0s - loss: 0.1454 - acc: 0.9498Epoch 00004: val_acc improved from 0.89149 to 0.89774, saving model to best_resnet_crop.h5\n",
      "1354/1354 [==============================] - 883s 652ms/step - loss: 0.1453 - acc: 0.9498 - val_loss: 0.3461 - val_acc: 0.8977\n",
      "Epoch 5/60\n",
      "1353/1354 [============================>.] - ETA: 0s - loss: 0.1422 - acc: 0.9520Epoch 00005: val_acc did not improve\n",
      "\n",
      "Epoch 00005: reducing learning rate to 2.499999936844688e-05.\n",
      "1354/1354 [==============================] - 883s 652ms/step - loss: 0.1421 - acc: 0.9521 - val_loss: 0.5652 - val_acc: 0.8400\n",
      "Epoch 6/60\n",
      "1353/1354 [============================>.] - ETA: 0s - loss: 0.1193 - acc: 0.9617Epoch 00006: val_acc did not improve\n",
      "1354/1354 [==============================] - 882s 652ms/step - loss: 0.1193 - acc: 0.9618 - val_loss: 0.4600 - val_acc: 0.8762\n",
      "Epoch 7/60\n",
      "1353/1354 [============================>.] - ETA: 0s - loss: 0.0986 - acc: 0.9675Epoch 00007: val_acc improved from 0.89774 to 0.89978, saving model to best_resnet_crop.h5\n",
      "1354/1354 [==============================] - 884s 653ms/step - loss: 0.0985 - acc: 0.9675 - val_loss: 0.3446 - val_acc: 0.8998\n",
      "Epoch 8/60\n",
      "1353/1354 [============================>.] - ETA: 0s - loss: 0.1043 - acc: 0.9649Epoch 00008: val_acc did not improve\n",
      "1354/1354 [==============================] - 882s 652ms/step - loss: 0.1043 - acc: 0.9648 - val_loss: 0.3725 - val_acc: 0.8931\n",
      "Epoch 9/60\n",
      "1353/1354 [============================>.] - ETA: 0s - loss: 0.0978 - acc: 0.9682Epoch 00009: val_acc improved from 0.89978 to 0.90319, saving model to best_resnet_crop.h5\n",
      "1354/1354 [==============================] - 884s 653ms/step - loss: 0.0978 - acc: 0.9682 - val_loss: 0.3426 - val_acc: 0.9032\n",
      "Epoch 10/60\n",
      "1353/1354 [============================>.] - ETA: 0s - loss: 0.1024 - acc: 0.9669Epoch 00010: val_acc improved from 0.90319 to 0.91285, saving model to best_resnet_crop.h5\n",
      "1354/1354 [==============================] - 884s 653ms/step - loss: 0.1023 - acc: 0.9669 - val_loss: 0.3120 - val_acc: 0.9129\n",
      "Epoch 11/60\n",
      "1353/1354 [============================>.] - ETA: 0s - loss: 0.0934 - acc: 0.9680Epoch 00011: val_acc improved from 0.91285 to 0.91331, saving model to best_resnet_crop.h5\n",
      "1354/1354 [==============================] - 884s 653ms/step - loss: 0.0933 - acc: 0.9681 - val_loss: 0.3078 - val_acc: 0.9133\n",
      "Epoch 12/60\n",
      "1353/1354 [============================>.] - ETA: 0s - loss: 0.0933 - acc: 0.9691Epoch 00012: val_acc did not improve\n",
      "1354/1354 [==============================] - 882s 652ms/step - loss: 0.0934 - acc: 0.9691 - val_loss: 0.4455 - val_acc: 0.8715\n",
      "Epoch 13/60\n",
      "1353/1354 [============================>.] - ETA: 0s - loss: 0.0902 - acc: 0.9702Epoch 00013: val_acc improved from 0.91331 to 0.91353, saving model to best_resnet_crop.h5\n",
      "1354/1354 [==============================] - 883s 653ms/step - loss: 0.0902 - acc: 0.9702 - val_loss: 0.3137 - val_acc: 0.9135\n",
      "Epoch 14/60\n",
      "1353/1354 [============================>.] - ETA: 0s - loss: 0.0925 - acc: 0.9685Epoch 00014: val_acc did not improve\n",
      "1354/1354 [==============================] - 882s 652ms/step - loss: 0.0925 - acc: 0.9685 - val_loss: 0.3528 - val_acc: 0.9015\n",
      "Epoch 15/60\n",
      "1353/1354 [============================>.] - ETA: 0s - loss: 0.0826 - acc: 0.9723Epoch 00015: val_acc did not improve\n",
      "1354/1354 [==============================] - 882s 652ms/step - loss: 0.0825 - acc: 0.9723 - val_loss: 0.4295 - val_acc: 0.8881\n",
      "Epoch 16/60\n",
      "1353/1354 [============================>.] - ETA: 0s - loss: 0.0906 - acc: 0.9690Epoch 00016: val_acc did not improve\n",
      "1354/1354 [==============================] - 882s 652ms/step - loss: 0.0906 - acc: 0.9690 - val_loss: 0.3265 - val_acc: 0.9082\n",
      "Epoch 17/60\n",
      "1353/1354 [============================>.] - ETA: 0s - loss: 0.0873 - acc: 0.9703Epoch 00017: val_acc did not improve\n",
      "1354/1354 [==============================] - 882s 652ms/step - loss: 0.0872 - acc: 0.9703 - val_loss: 0.3609 - val_acc: 0.9019\n",
      "Epoch 18/60\n",
      "1353/1354 [============================>.] - ETA: 0s - loss: 0.0832 - acc: 0.9713Epoch 00018: val_acc did not improve\n",
      "1354/1354 [==============================] - 882s 652ms/step - loss: 0.0831 - acc: 0.9714 - val_loss: 0.3242 - val_acc: 0.9113\n",
      "Epoch 19/60\n",
      "1353/1354 [============================>.] - ETA: 0s - loss: 0.0861 - acc: 0.9710Epoch 00019: val_acc improved from 0.91353 to 0.91796, saving model to best_resnet_crop.h5\n",
      "\n",
      "Epoch 00019: reducing learning rate to 1.249999968422344e-05.\n",
      "1354/1354 [==============================] - 884s 653ms/step - loss: 0.0860 - acc: 0.9710 - val_loss: 0.3031 - val_acc: 0.9180\n",
      "Epoch 20/60\n",
      "1353/1354 [============================>.] - ETA: 0s - loss: 0.0758 - acc: 0.9746Epoch 00020: val_acc improved from 0.91796 to 0.93251, saving model to best_resnet_crop.h5\n",
      "1354/1354 [==============================] - 883s 652ms/step - loss: 0.0757 - acc: 0.9746 - val_loss: 0.2498 - val_acc: 0.9325\n",
      "Epoch 21/60\n",
      "1353/1354 [============================>.] - ETA: 0s - loss: 0.0678 - acc: 0.9775Epoch 00021: val_acc did not improve\n",
      "1354/1354 [==============================] - 882s 652ms/step - loss: 0.0678 - acc: 0.9775 - val_loss: 0.2781 - val_acc: 0.9250\n",
      "Epoch 22/60\n",
      "1353/1354 [============================>.] - ETA: 0s - loss: 0.0694 - acc: 0.9774Epoch 00022: val_acc did not improve\n",
      "1354/1354 [==============================] - 882s 652ms/step - loss: 0.0695 - acc: 0.9773 - val_loss: 0.2844 - val_acc: 0.9235\n",
      "Epoch 23/60\n",
      "1353/1354 [============================>.] - ETA: 0s - loss: 0.0693 - acc: 0.9767Epoch 00023: val_acc did not improve\n",
      "1354/1354 [==============================] - 882s 651ms/step - loss: 0.0692 - acc: 0.9768 - val_loss: 0.2646 - val_acc: 0.9267\n",
      "Epoch 24/60\n",
      "1353/1354 [============================>.] - ETA: 0s - loss: 0.0666 - acc: 0.9783Epoch 00024: val_acc did not improve\n",
      "1354/1354 [==============================] - 882s 651ms/step - loss: 0.0666 - acc: 0.9783 - val_loss: 0.2714 - val_acc: 0.9288\n",
      "Epoch 25/60\n",
      "1353/1354 [============================>.] - ETA: 0s - loss: 0.0643 - acc: 0.9783Epoch 00025: val_acc did not improve\n",
      "1354/1354 [==============================] - 882s 651ms/step - loss: 0.0643 - acc: 0.9783 - val_loss: 0.3354 - val_acc: 0.9109\n",
      "Epoch 26/60\n",
      "1353/1354 [============================>.] - ETA: 0s - loss: 0.0670 - acc: 0.9787Epoch 00026: val_acc did not improve\n",
      "1354/1354 [==============================] - 882s 652ms/step - loss: 0.0670 - acc: 0.9787 - val_loss: 0.2783 - val_acc: 0.9252\n",
      "Epoch 27/60\n",
      "1353/1354 [============================>.] - ETA: 0s - loss: 0.0604 - acc: 0.9806Epoch 00027: val_acc did not improve\n",
      "1354/1354 [==============================] - 882s 652ms/step - loss: 0.0604 - acc: 0.9806 - val_loss: 0.2867 - val_acc: 0.9242\n",
      "Epoch 28/60\n",
      "1353/1354 [============================>.] - ETA: 0s - loss: 0.0643 - acc: 0.9789Epoch 00028: val_acc did not improve\n",
      "1354/1354 [==============================] - 882s 651ms/step - loss: 0.0644 - acc: 0.9789 - val_loss: 0.2774 - val_acc: 0.9252\n",
      "Epoch 29/60\n",
      "1353/1354 [============================>.] - ETA: 0s - loss: 0.0650 - acc: 0.9782Epoch 00029: val_acc did not improve\n",
      "1354/1354 [==============================] - 882s 651ms/step - loss: 0.0649 - acc: 0.9782 - val_loss: 0.2852 - val_acc: 0.9249\n",
      "Epoch 30/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1353/1354 [============================>.] - ETA: 0s - loss: 0.0604 - acc: 0.9798Epoch 00030: val_acc did not improve\n",
      "1354/1354 [==============================] - 880s 650ms/step - loss: 0.0603 - acc: 0.9798 - val_loss: 0.2620 - val_acc: 0.9282\n",
      "Epoch 31/60\n",
      "1353/1354 [============================>.] - ETA: 0s - loss: 0.0586 - acc: 0.9808Epoch 00031: val_acc did not improve\n",
      "1354/1354 [==============================] - 880s 650ms/step - loss: 0.0586 - acc: 0.9809 - val_loss: 0.3722 - val_acc: 0.9035\n",
      "Epoch 32/60\n",
      "1353/1354 [============================>.] - ETA: 0s - loss: 0.0564 - acc: 0.9821Epoch 00032: val_acc did not improve\n",
      "1354/1354 [==============================] - 881s 650ms/step - loss: 0.0564 - acc: 0.9822 - val_loss: 0.2827 - val_acc: 0.9269\n",
      "Epoch 33/60\n",
      "1353/1354 [============================>.] - ETA: 0s - loss: 0.0591 - acc: 0.9807Epoch 00033: val_acc did not improve\n",
      "1354/1354 [==============================] - 880s 650ms/step - loss: 0.0592 - acc: 0.9807 - val_loss: 0.3038 - val_acc: 0.9236\n",
      "Epoch 34/60\n",
      "1353/1354 [============================>.] - ETA: 0s - loss: 0.0557 - acc: 0.9810Epoch 00034: val_acc did not improve\n",
      "1354/1354 [==============================] - 880s 650ms/step - loss: 0.0556 - acc: 0.9810 - val_loss: 0.2693 - val_acc: 0.9298\n",
      "Epoch 35/60\n",
      "1353/1354 [============================>.] - ETA: 0s - loss: 0.0576 - acc: 0.9807Epoch 00035: val_acc did not improve\n",
      "1354/1354 [==============================] - 880s 650ms/step - loss: 0.0576 - acc: 0.9807 - val_loss: 0.2925 - val_acc: 0.9263\n",
      "Epoch 36/60\n",
      "1353/1354 [============================>.] - ETA: 0s - loss: 0.0588 - acc: 0.9809Epoch 00036: val_acc did not improve\n",
      "1354/1354 [==============================] - 880s 650ms/step - loss: 0.0588 - acc: 0.9809 - val_loss: 0.2703 - val_acc: 0.9306\n",
      "Epoch 37/60\n",
      "1353/1354 [============================>.] - ETA: 0s - loss: 0.0535 - acc: 0.9817Epoch 00037: val_acc did not improve\n",
      "1354/1354 [==============================] - 880s 650ms/step - loss: 0.0534 - acc: 0.9817 - val_loss: 0.3228 - val_acc: 0.9181\n",
      "Epoch 38/60\n",
      "1353/1354 [============================>.] - ETA: 0s - loss: 0.0585 - acc: 0.9794Epoch 00038: val_acc did not improve\n",
      "1354/1354 [==============================] - 880s 650ms/step - loss: 0.0585 - acc: 0.9794 - val_loss: 0.2946 - val_acc: 0.9221\n",
      "Epoch 39/60\n",
      "1353/1354 [============================>.] - ETA: 0s - loss: 0.0597 - acc: 0.9800Epoch 00039: val_acc did not improve\n",
      "1354/1354 [==============================] - 880s 650ms/step - loss: 0.0596 - acc: 0.9801 - val_loss: 0.2969 - val_acc: 0.9233\n",
      "Epoch 40/60\n",
      "1353/1354 [============================>.] - ETA: 0s - loss: 0.0581 - acc: 0.9815Epoch 00040: val_acc did not improve\n",
      "1354/1354 [==============================] - 880s 650ms/step - loss: 0.0581 - acc: 0.9814 - val_loss: 0.3094 - val_acc: 0.9204\n",
      "Epoch 41/60\n",
      "1353/1354 [============================>.] - ETA: 0s - loss: 0.0555 - acc: 0.9808Epoch 00041: val_acc did not improve\n",
      "\n",
      "Epoch 00041: reducing learning rate to 6.24999984211172e-06.\n",
      "1354/1354 [==============================] - 880s 650ms/step - loss: 0.0554 - acc: 0.9808 - val_loss: 0.3687 - val_acc: 0.9069\n",
      "Epoch 42/60\n",
      "1353/1354 [============================>.] - ETA: 0s - loss: 0.0479 - acc: 0.9846Epoch 00042: val_acc improved from 0.93251 to 0.93319, saving model to best_resnet_crop.h5\n",
      "1354/1354 [==============================] - 881s 651ms/step - loss: 0.0479 - acc: 0.9846 - val_loss: 0.2623 - val_acc: 0.9332\n",
      "Epoch 43/60\n",
      "1353/1354 [============================>.] - ETA: 0s - loss: 0.0499 - acc: 0.9835Epoch 00043: val_acc did not improve\n",
      "1354/1354 [==============================] - 880s 650ms/step - loss: 0.0498 - acc: 0.9835 - val_loss: 0.2825 - val_acc: 0.9271\n",
      "Epoch 44/60\n",
      "1353/1354 [============================>.] - ETA: 0s - loss: 0.0469 - acc: 0.9850Epoch 00044: val_acc improved from 0.93319 to 0.93330, saving model to best_resnet_crop.h5\n",
      "1354/1354 [==============================] - 881s 651ms/step - loss: 0.0469 - acc: 0.9851 - val_loss: 0.2558 - val_acc: 0.9333\n",
      "Epoch 45/60\n",
      "1353/1354 [============================>.] - ETA: 0s - loss: 0.0460 - acc: 0.9860Epoch 00045: val_acc improved from 0.93330 to 0.93342, saving model to best_resnet_crop.h5\n",
      "1354/1354 [==============================] - 881s 651ms/step - loss: 0.0460 - acc: 0.9860 - val_loss: 0.2554 - val_acc: 0.9334\n",
      "Epoch 46/60\n",
      "1353/1354 [============================>.] - ETA: 0s - loss: 0.0430 - acc: 0.9860Epoch 00046: val_acc did not improve\n",
      "1354/1354 [==============================] - 880s 650ms/step - loss: 0.0430 - acc: 0.9860 - val_loss: 0.2682 - val_acc: 0.9300\n",
      "Epoch 47/60\n",
      "1353/1354 [============================>.] - ETA: 0s - loss: 0.0457 - acc: 0.9856Epoch 00047: val_acc did not improve\n",
      "1354/1354 [==============================] - 880s 650ms/step - loss: 0.0456 - acc: 0.9856 - val_loss: 0.2824 - val_acc: 0.9260\n",
      "Epoch 48/60\n",
      "1353/1354 [============================>.] - ETA: 0s - loss: 0.0420 - acc: 0.9870Epoch 00048: val_acc did not improve\n",
      "1354/1354 [==============================] - 880s 650ms/step - loss: 0.0420 - acc: 0.9870 - val_loss: 0.2624 - val_acc: 0.9331\n",
      "Epoch 49/60\n",
      "1353/1354 [============================>.] - ETA: 0s - loss: 0.0441 - acc: 0.9852Epoch 00049: val_acc did not improve\n",
      "1354/1354 [==============================] - 880s 650ms/step - loss: 0.0440 - acc: 0.9852 - val_loss: 0.2640 - val_acc: 0.9323\n",
      "Epoch 50/60\n",
      "1353/1354 [============================>.] - ETA: 0s - loss: 0.0431 - acc: 0.9858Epoch 00050: val_acc did not improve\n",
      "1354/1354 [==============================] - 880s 650ms/step - loss: 0.0431 - acc: 0.9858 - val_loss: 0.2853 - val_acc: 0.9280\n",
      "Epoch 51/60\n",
      "1353/1354 [============================>.] - ETA: 0s - loss: 0.0484 - acc: 0.9839Epoch 00051: val_acc did not improve\n",
      "1354/1354 [==============================] - 880s 650ms/step - loss: 0.0484 - acc: 0.9839 - val_loss: 0.2842 - val_acc: 0.9281\n",
      "Epoch 52/60\n",
      "1353/1354 [============================>.] - ETA: 0s - loss: 0.0442 - acc: 0.9844Epoch 00052: val_acc did not improve\n",
      "\n",
      "Epoch 00052: reducing learning rate to 3.12499992105586e-06.\n",
      "1354/1354 [==============================] - 880s 650ms/step - loss: 0.0441 - acc: 0.9844 - val_loss: 0.2666 - val_acc: 0.9313\n",
      "Epoch 53/60\n",
      "1353/1354 [============================>.] - ETA: 0s - loss: 0.0428 - acc: 0.9865Epoch 00053: val_acc improved from 0.93342 to 0.93705, saving model to best_resnet_crop.h5\n",
      "1354/1354 [==============================] - 881s 651ms/step - loss: 0.0428 - acc: 0.9865 - val_loss: 0.2479 - val_acc: 0.9371\n",
      "Epoch 54/60\n",
      "1353/1354 [============================>.] - ETA: 0s - loss: 0.0382 - acc: 0.9887Epoch 00054: val_acc did not improve\n",
      "1354/1354 [==============================] - 880s 650ms/step - loss: 0.0382 - acc: 0.9888 - val_loss: 0.2565 - val_acc: 0.9355\n",
      "Epoch 55/60\n",
      "1353/1354 [============================>.] - ETA: 0s - loss: 0.0401 - acc: 0.9871Epoch 00055: val_acc improved from 0.93705 to 0.93864, saving model to best_resnet_crop.h5\n",
      "1354/1354 [==============================] - 881s 651ms/step - loss: 0.0401 - acc: 0.9871 - val_loss: 0.2402 - val_acc: 0.9386\n",
      "Epoch 56/60\n",
      "1353/1354 [============================>.] - ETA: 0s - loss: 0.0407 - acc: 0.9868Epoch 00056: val_acc did not improve\n",
      "1354/1354 [==============================] - 880s 650ms/step - loss: 0.0407 - acc: 0.9868 - val_loss: 0.2448 - val_acc: 0.9360\n",
      "Epoch 57/60\n",
      "1353/1354 [============================>.] - ETA: 0s - loss: 0.0388 - acc: 0.9882Epoch 00057: val_acc did not improve\n",
      "1354/1354 [==============================] - 880s 650ms/step - loss: 0.0388 - acc: 0.9882 - val_loss: 0.2564 - val_acc: 0.9348\n",
      "Epoch 58/60\n",
      "1353/1354 [============================>.] - ETA: 0s - loss: 0.0381 - acc: 0.9879Epoch 00058: val_acc did not improve\n",
      "1354/1354 [==============================] - 880s 650ms/step - loss: 0.0381 - acc: 0.9879 - val_loss: 0.2508 - val_acc: 0.9358\n",
      "Epoch 59/60\n",
      "1353/1354 [============================>.] - ETA: 0s - loss: 0.0379 - acc: 0.9886Epoch 00059: val_acc did not improve\n",
      "1354/1354 [==============================] - 880s 650ms/step - loss: 0.0378 - acc: 0.9886 - val_loss: 0.2540 - val_acc: 0.9351\n",
      "Epoch 60/60\n",
      "1353/1354 [============================>.] - ETA: 0s - loss: 0.0393 - acc: 0.9874Epoch 00060: val_acc did not improve\n",
      "1354/1354 [==============================] - 880s 650ms/step - loss: 0.0392 - acc: 0.9874 - val_loss: 0.2490 - val_acc: 0.9338\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f902853c3c8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_chk = ModelCheckpoint(filepath=model_p, monitor='val_acc', save_best_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.5, verbose=1,\n",
    "                              patience=3, min_lr=0.00000001)\n",
    "\n",
    "model.fit_generator(train_gen,\n",
    "          steps_per_epoch = train_step,\n",
    "          epochs=60,\n",
    "          validation_data = valid_gen,\n",
    "          validation_steps = valid_step,\n",
    "          callbacks=[model_chk,reduce_lr]\n",
    "         )\n",
    "\n",
    "# Epoch 00092: val_acc improved from 0.88524 to 0.89842, saving model to best_resnet_crop.h5\n",
    "# 1354/1354 [==============================] - 884s \n",
    "# 653ms/step - loss: 0.1565 - acc: 0.9449 - val_loss: 0.3287 - val_acc: 0.8984\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  4.95690822e-10   1.35712570e-03   5.03167108e-08   3.10969446e-03\n",
      "    1.08761049e-03   2.06841531e-08   8.60702188e-04   9.93148744e-01\n",
      "    4.40775494e-07   4.35597991e-04]\n",
      " [  1.31894582e-12   1.28995581e-09   1.12423898e-07   2.89413110e-05\n",
      "    1.98374025e-07   9.99712646e-01   2.00872591e-06   3.49607898e-09\n",
      "    1.08468923e-08   2.55942025e-04]\n",
      " [  1.02780084e-03   7.05446102e-09   8.94968707e-06   4.10328958e-11\n",
      "    5.09730178e-08   6.98557514e-08   9.98858094e-01   8.30362260e-05\n",
      "    7.14190946e-08   2.19450958e-05]\n",
      " [  1.18031224e-10   1.55000598e-05   2.37870040e-06   2.82170859e-05\n",
      "    1.64574736e-08   1.17564687e-08   4.98017243e-07   4.87251928e-05\n",
      "    9.99701798e-01   2.02797950e-04]\n",
      " [  1.89537581e-18   9.99991536e-01   1.24827058e-11   7.59331579e-06\n",
      "    4.83203699e-09   1.43185797e-09   4.01544978e-11   4.79705664e-10\n",
      "    8.20581079e-07   6.89134722e-11]]\n"
     ]
    }
   ],
   "source": [
    "best_model = load_model(model_p)\n",
    "test_y = []\n",
    "for img_p in test_files:\n",
    "    tmp_x = get_test_img(img_p)\n",
    "    tmp_y = best_model.predict(np.array([tmp_x]))[0]\n",
    "    test_y.append(tmp_y)\n",
    "\n",
    "test_y = np.array(test_y)\n",
    "print(test_y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   fname    camera\n",
      "0  img_0002a04_manip.tif  iPhone-6\n",
      "1  img_001e31c_unalt.tif  iPhone-6\n",
      "2  img_00275cf_manip.tif  iPhone-6\n",
      "3  img_0034113_unalt.tif  iPhone-6\n",
      "4  img_00344b7_unalt.tif  iPhone-6\n",
      "                   fname             camera\n",
      "0  img_0002a04_manip.tif        LG-Nexus-5x\n",
      "1  img_001e31c_unalt.tif          iPhone-4s\n",
      "2  img_00275cf_manip.tif           iPhone-6\n",
      "3  img_0034113_unalt.tif  Samsung-Galaxy-S4\n",
      "4  img_00344b7_unalt.tif         Motorola-X\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "y_res = np.argmax(test_y,axis=1)\n",
    "y_res = [list_classes[i] for i in y_res]\n",
    "df = pd.read_csv('../input/sample_submission.csv')\n",
    "print(df.head())\n",
    "f_name = [p.split('/')[-1] for p in test_files]\n",
    "df['fname'] = f_name\n",
    "df['camera'] = y_res\n",
    "print(df.head())\n",
    "df.to_csv('../results/resnet_manip_crop.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 224, 224, 3)\n",
      "(5, 10)\n",
      "[  1.87444730e-05   6.01468608e-03   7.86853582e-02   1.20262019e-02\n",
      "   5.61773330e-02   3.00654847e-05   7.20329909e-03   4.83296347e+00\n",
      "   4.75997850e-03   2.12072022e-03]\n",
      "[[  1.87444730e-05   6.01468608e-03   7.86853582e-02   1.20262019e-02\n",
      "    5.61773330e-02   3.00654847e-05   7.20329909e-03   4.83296347e+00\n",
      "    4.75997850e-03   2.12072022e-03]\n",
      " [  2.79381857e-06   3.18503469e-01   3.41931544e-02   7.53534187e-05\n",
      "    1.29285842e-01   4.47995043e+00   1.08112639e-03   5.43277274e-05\n",
      "    3.80140234e-04   3.64731401e-02]\n",
      " [  2.12826245e-02   5.70476279e-02   4.83377837e-03   3.26004374e-05\n",
      "    3.05653375e-04   1.01136757e-04   4.16344023e+00   7.52126575e-01\n",
      "    1.08164486e-05   8.19124631e-04]\n",
      " [  3.82197030e-08   4.04749345e-03   1.05198487e-05   5.51818346e-04\n",
      "    8.85308339e-07   2.89436116e-06   1.34401453e-05   7.45816797e-05\n",
      "    4.99478960e+00   5.08665922e-04]\n",
      " [  7.43690332e-10   4.99917555e+00   1.40806005e-04   2.57210068e-05\n",
      "    6.78630499e-07   1.56798051e-05   2.21391128e-09   1.86033485e-05\n",
      "    6.22734253e-04   3.50015000e-07]]\n",
      "                   fname             camera\n",
      "0  img_0002a04_manip.tif        LG-Nexus-5x\n",
      "1  img_001e31c_unalt.tif          iPhone-4s\n",
      "2  img_00275cf_manip.tif           iPhone-6\n",
      "3  img_0034113_unalt.tif  Samsung-Galaxy-S4\n",
      "4  img_00344b7_unalt.tif         Motorola-X\n"
     ]
    }
   ],
   "source": [
    "# TTA\n",
    "def get_tta_img(img_path):\n",
    "    im_array = np.array(Image.open((img_path)), dtype=\"uint8\")\n",
    "    im_array = im_array/127.5\n",
    "    im_array = im_array - 1.0\n",
    "    img_list = []\n",
    "    img_list.append(center_crop(im_array))\n",
    "#     for i in range(4):\n",
    "#         for j in range(3):\n",
    "#             a = i*72\n",
    "#             b = a + 224\n",
    "#             c = j*96\n",
    "#             d = c + 224\n",
    "#             #print(a,b,c,d)\n",
    "#             img_list.append(im_array[a:b,c:d,:])\n",
    "    img_list.append(im_array[0:CROP_LEN,0:CROP_LEN,:])\n",
    "    img_list.append(im_array[0:CROP_LEN,512-CROP_LEN:512,:])\n",
    "    img_list.append(im_array[512-CROP_LEN:512,0:CROP_LEN,:])\n",
    "    img_list.append(im_array[512-CROP_LEN:512,512-CROP_LEN:512,:])\n",
    "    return np.array(img_list)\n",
    "tta_img = get_tta_img(test_files[0])\n",
    "print(tta_img.shape)\n",
    "tta_res = best_model.predict(tta_img)\n",
    "print(tta_res.shape)\n",
    "print(np.sum(tta_res,axis=0))\n",
    "\n",
    "test_y = []\n",
    "for img_p in test_files:\n",
    "    tmp_x = get_tta_img(img_p)\n",
    "    tmp_y = best_model.predict(tmp_x)\n",
    "    tmp_y = np.sum(tmp_y,axis=0)\n",
    "    test_y.append(tmp_y)\n",
    "\n",
    "test_y = np.array(test_y)\n",
    "print(test_y[:5])\n",
    "\n",
    "y_res = np.argmax(test_y,axis=1)\n",
    "y_res = [list_classes[i] for i in y_res]\n",
    "df = pd.read_csv('../input/sample_submission.csv')\n",
    "f_name = [p.split('/')[-1] for p in test_files]\n",
    "df['fname'] = f_name\n",
    "df['camera'] = y_res\n",
    "print(df.head())\n",
    "df.to_csv('../results/resnet_manip_crop_tta.csv',index=False)  # score 804"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
