{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Sony-NEX-7': [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'Motorola-Nexus-6': [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], 'Motorola-X': [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], 'iPhone-6': [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], 'Motorola-Droid-Maxx': [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], 'Samsung-Galaxy-Note3': [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], 'HTC-1-M7': [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], 'Samsung-Galaxy-S4': [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], 'iPhone-4s': [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], 'LG-Nexus-5x': [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import skimage\n",
    "import skimage.io\n",
    "import scipy.misc\n",
    "import imageio\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "\n",
    "list_classes = [\n",
    " 'Sony-NEX-7',\n",
    " 'Motorola-X',\n",
    " 'HTC-1-M7',\n",
    " 'Samsung-Galaxy-Note3',\n",
    " 'Motorola-Droid-Maxx',\n",
    " 'iPhone-4s',\n",
    " 'iPhone-6',\n",
    " 'LG-Nexus-5x',\n",
    " 'Samsung-Galaxy-S4',\n",
    " 'Motorola-Nexus-6']\n",
    "\n",
    "list_dict = {}\n",
    "for i in range(10):\n",
    "    key = list_classes[i]\n",
    "    v = [0,0,0,0,0,0,0,0,0,0]\n",
    "    v[i] = 1\n",
    "    list_dict[key] = v\n",
    "print(list_dict)\n",
    "\n",
    "train_dir = '../input/train'\n",
    "test_dir = '../input/test'\n",
    "test_files = sorted(glob.glob(test_dir+'/*'))\n",
    "train_files = sorted(glob.glob(train_dir+'/*/*'))\n",
    "train_data_cnt = len(train_files)\n",
    "BATCH_SIZE = 48\n",
    "CROP_LEN = 112\n",
    "\n",
    "def random_crop(im_array):\n",
    "    # crop\n",
    "    x_range = im_array.shape[0] - CROP_LEN\n",
    "    y_range = im_array.shape[1] - CROP_LEN\n",
    "    # print(x_range,y_range)\n",
    "    a = np.random.randint(x_range)\n",
    "    b = a + CROP_LEN\n",
    "    c = np.random.randint(y_range)\n",
    "    d = c + CROP_LEN\n",
    "    new_im_array = im_array[a:b,c:d,:]\n",
    "    return new_im_array\n",
    "\n",
    "def center_crop(im_array):\n",
    "    center_x = im_array.shape[0] // 2\n",
    "    center_y = im_array.shape[1] // 2\n",
    "    half_crop = CROP_LEN // 2\n",
    "    a = center_x - half_crop\n",
    "    b = a + CROP_LEN\n",
    "    c = center_y - half_crop\n",
    "    d = c + CROP_LEN\n",
    "    new_im_array = im_array[a:b,c:d,:]\n",
    "    return new_im_array\n",
    "    \n",
    "\n",
    "def random_manip(img,rnd):\n",
    "    if rnd == 0:\n",
    "        return img\n",
    "    \n",
    "    elif rnd == 1:\n",
    "        # gamma 0.8\n",
    "        new_img = skimage.exposure.adjust_gamma(img, gamma=0.8)\n",
    "        return new_img\n",
    "    \n",
    "    elif rnd == 2:\n",
    "        # gamma 1.2\n",
    "        new_img = skimage.exposure.adjust_gamma(img, gamma=1.2)\n",
    "        return new_img\n",
    "    \n",
    "    elif rnd == 3:\n",
    "        # jpeg 70\n",
    "        imageio.imwrite('/tmp/quality-70.jpg', img, quality=70)\n",
    "        try:\n",
    "            new_img = np.array(Image.open(('/tmp/quality-70.jpg')), dtype=\"uint8\")\n",
    "            os.remove('/tmp/quality-70.jpg')\n",
    "            return new_img\n",
    "        except:\n",
    "            return img\n",
    "    \n",
    "    elif rnd == 4:\n",
    "        # jpeg 90\n",
    "        imageio.imwrite('/tmp/quality-90.jpg', img, quality=90)\n",
    "        try:\n",
    "            new_img = np.array(Image.open(('/tmp/quality-90.jpg')), dtype=\"uint8\")\n",
    "            os.remove('/tmp/quality-90.jpg')\n",
    "            return new_img\n",
    "        except:\n",
    "            return img\n",
    "    \n",
    "    elif rnd == 5:\n",
    "        # 2x of original image\n",
    "        new_img = scipy.misc.imresize(img, 2.0, interp='bicubic')\n",
    "        return center_crop(new_img)\n",
    "    \n",
    "    elif rnd == 6:\n",
    "        new_img = scipy.misc.imresize(img, 1.5, interp='bicubic')\n",
    "        return center_crop(new_img)\n",
    "    \n",
    "    elif rnd == 7:\n",
    "        new_img = scipy.misc.imresize(img, 0.5, interp='bicubic')\n",
    "        return new_img\n",
    "    \n",
    "    elif rnd == 8:\n",
    "        new_img = scipy.misc.imresize(img, 0.8, interp='bicubic')\n",
    "        return new_img\n",
    "    \n",
    "    else:\n",
    "        return img\n",
    "\n",
    "def get_img(img_path, train_flag = True, fake_rnd = 0):\n",
    "    # read img\n",
    "    im_array = np.array(Image.open((img_path)), dtype=\"uint8\")\n",
    "    \n",
    "    # train or valid\n",
    "    if train_flag is True:\n",
    "        # manip rnd\n",
    "        manip_rnd = np.random.randint(16) # only half manip, 1 to 8 use manip\n",
    "        #manip_rnd = 5\n",
    "        #print(manip_rnd,im_array.shape)\n",
    "        if manip_rnd < 7 or manip_rnd > 8 : \n",
    "            # no zoom in， 随机切出 224\n",
    "            im_array = random_crop(im_array)\n",
    "            # manip， 随机变化，如果放大则去中间部分\n",
    "            final_img = random_manip(im_array, manip_rnd)\n",
    "          \n",
    "        else:\n",
    "            # resize zoom out， 缩小\n",
    "            im_array = random_manip(im_array, manip_rnd)\n",
    "            # random crop on larger image， 随机切出 224\n",
    "            final_img = random_crop(im_array)\n",
    "        if final_img.shape[0]!=CROP_LEN or final_img.shape[1]!=CROP_LEN:\n",
    "            print('train',manip_rnd,final_img.shape,img_path,im_array.shape)\n",
    "    else:\n",
    "        # center crop for valid data\n",
    "        # manip rnd\n",
    "        manip_rnd = fake_rnd % 16\n",
    "        if manip_rnd < 7 or manip_rnd > 8 :\n",
    "            # no zoom in， 取中间部分\n",
    "            im_array = center_crop(im_array)\n",
    "            # manip, 随机变化，如果放大则取中间部分\n",
    "            final_img = random_manip(im_array, manip_rnd)\n",
    "        else:\n",
    "            # resize zoom out, 先缩小图片\n",
    "            im_array = random_manip(im_array, manip_rnd)\n",
    "            # random crop on larger image, 取中间部分\n",
    "            final_img = center_crop(im_array)\n",
    "        if final_img.shape[0]!=CROP_LEN or final_img.shape[1]!=CROP_LEN:\n",
    "            print('valid',manip_rnd,final_img.shape,img_path,im_array.shape)\n",
    "    \n",
    "    final_img = final_img/255.0\n",
    "    return final_img\n",
    "\n",
    "# 读取测试数据中间 112\n",
    "def get_test_img(img_path):\n",
    "    # read img\n",
    "    im_array = np.array(Image.open((img_path)), dtype=\"uint8\")\n",
    "    final_img = center_crop(im_array)\n",
    "    final_img = final_img/255.0\n",
    "    return final_img\n",
    "\n",
    "def get_y(img_path):\n",
    "    n = img_path.split('/')[-2]\n",
    "    return list_dict[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48, 112, 112, 3) (48, 10)\n",
      "float32\n",
      "[[0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1]\n",
      " [1 0 0 0 0 0 0 0 0 0]]\n",
      "(48, 112, 112, 3) (48, 10)\n",
      "float32\n",
      "[[0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1]\n",
      " [1 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "def data_gen(file_list, batch_size=BATCH_SIZE, train_flag = True):\n",
    "    curr_idx = 0\n",
    "    data_cnt = len(file_list)\n",
    "    fake_rnd = 0\n",
    "    while True:\n",
    "        if curr_idx + batch_size > data_cnt:\n",
    "            start_idx = data_cnt-batch_size\n",
    "            end_idx = data_cnt\n",
    "            curr_idx = 0\n",
    "        else:\n",
    "            start_idx = curr_idx\n",
    "            end_idx = curr_idx + batch_size\n",
    "            curr_idx += batch_size\n",
    "        curr_fl = file_list[start_idx:end_idx]\n",
    "        if train_flag is True:\n",
    "            curr_x = np.array([get_img(p,train_flag) for p in curr_fl],dtype='float32')\n",
    "        else:\n",
    "            # make validation data stable\n",
    "            curr_x = []\n",
    "            for p in curr_fl:\n",
    "                tmp_img = get_img(p,train_flag,fake_rnd)\n",
    "                curr_x.append(tmp_img)\n",
    "                fake_rnd += 1\n",
    "                fake_rnd = fake_rnd % 16\n",
    "            curr_x = np.array(curr_x,dtype='float32')\n",
    "        curr_y = np.array([get_y(p) for p in curr_fl])\n",
    "        yield curr_x,curr_y\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "train_files = shuffle(train_files,random_state=42)\n",
    "\n",
    "\n",
    "train_gen = data_gen(train_files, BATCH_SIZE, True)\n",
    "valid_gen = data_gen(train_files, BATCH_SIZE, False)\n",
    "import math\n",
    "train_step = math.ceil(train_data_cnt/BATCH_SIZE)\n",
    "valid_step = train_step\n",
    "\n",
    "# test\n",
    "for x,y in train_gen:\n",
    "    print(x.shape,y.shape)\n",
    "    print(x.dtype)\n",
    "    print(y[:3])\n",
    "    break\n",
    "    \n",
    "# test\n",
    "for x,y in valid_gen:\n",
    "    print(x.shape,y.shape)\n",
    "    print(x.dtype)\n",
    "    print(y[:3])\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# def model\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout, Flatten, Lambda, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint,ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load best_xception_manip.h5\n",
      "Epoch 1/100\n",
      "57/58 [============================>.] - ETA: 9s - loss: 1.0613 - acc: 0.6301 Epoch 00001: val_acc improved from -inf to 0.61099, saving model to best_xception_manip.h5\n",
      "58/58 [==============================] - 1082s 19s/step - loss: 1.0590 - acc: 0.6318 - val_loss: 1.1149 - val_acc: 0.6110\n",
      "Epoch 2/100\n",
      "57/58 [============================>.] - ETA: 7s - loss: 1.0380 - acc: 0.6436 Epoch 00002: val_acc improved from 0.61099 to 0.63649, saving model to best_xception_manip.h5\n",
      "58/58 [==============================] - 1022s 18s/step - loss: 1.0387 - acc: 0.6444 - val_loss: 1.0350 - val_acc: 0.6365\n",
      "Epoch 3/100\n",
      "57/58 [============================>.] - ETA: 8s - loss: 1.0411 - acc: 0.6425 Epoch 00003: val_acc did not improve\n",
      "58/58 [==============================] - 1085s 19s/step - loss: 1.0399 - acc: 0.6426 - val_loss: 1.0424 - val_acc: 0.6275\n",
      "Epoch 4/100\n",
      "57/58 [============================>.] - ETA: 8s - loss: 1.0302 - acc: 0.6473 Epoch 00004: val_acc improved from 0.63649 to 0.64045, saving model to best_xception_manip.h5\n",
      "58/58 [==============================] - 1142s 20s/step - loss: 1.0272 - acc: 0.6491 - val_loss: 1.0324 - val_acc: 0.6404\n",
      "Epoch 5/100\n",
      "57/58 [============================>.] - ETA: 8s - loss: 1.0409 - acc: 0.6447 Epoch 00005: val_acc did not improve\n",
      "58/58 [==============================] - 1143s 20s/step - loss: 1.0410 - acc: 0.6440 - val_loss: 1.0461 - val_acc: 0.6390\n",
      "Epoch 6/100\n",
      "57/58 [============================>.] - ETA: 10s - loss: 1.0365 - acc: 0.6440"
     ]
    }
   ],
   "source": [
    "model_p = 'best_xception_manip.h5'\n",
    "\n",
    "if os.path.exists(model_p):\n",
    "    model = load_model(model_p)\n",
    "    # K.set_value(model.optimizer.lr, 0.0001)\n",
    "    print('load',model_p)\n",
    "else:\n",
    "    from keras.applications.xception import Xception\n",
    "    model = Xception(input_shape=(CROP_LEN,CROP_LEN,3),include_top=True,weights=None,classes=10)\n",
    "    print('get model')\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(0.001), metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "model_chk = ModelCheckpoint(filepath=model_p, monitor='val_acc', save_best_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.5, verbose=1,\n",
    "                              patience=3, min_lr=0.00000001)\n",
    "model.fit_generator(train_gen,\n",
    "          steps_per_epoch = train_step,\n",
    "          epochs=100,\n",
    "          validation_data = valid_gen,\n",
    "          validation_steps = valid_step,\n",
    "          callbacks=[model_chk,reduce_lr]\n",
    "         )\n",
    "\n",
    "# 2018-02-01\n",
    "# Epoch 87/100\n",
    "# 84/85 [============================>.] - ETA: 5s - loss: 1.1034 - acc: 0.6150 \n",
    "# Epoch 00087: val_acc improved from 0.62022 to 0.62059, saving model to best_xception_manip.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_model = load_model(model_p)\n",
    "test_y = []\n",
    "for img_p in test_files:\n",
    "    tmp_x = get_test_img(img_p)\n",
    "    tmp_y = best_model.predict(np.array([tmp_x]))[0]\n",
    "    test_y.append(tmp_y)\n",
    "\n",
    "test_y = np.array(test_y)\n",
    "print(test_y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "y_res = np.argmax(test_y,axis=1)\n",
    "y_res = [list_classes[i] for i in y_res]\n",
    "df = pd.read_csv('../input/sample_submission.csv')\n",
    "print(df.head())\n",
    "f_name = [p.split('/')[-1] for p in test_files]\n",
    "df['fname'] = f_name\n",
    "df['camera'] = y_res\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.to_csv('../results/xception_112_manip.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TTA\n",
    "def get_tta_img(img_path):\n",
    "    im_array = np.array(Image.open((img_path)), dtype=\"uint8\")\n",
    "    im_array = im_array/255.0\n",
    "    img_list = []\n",
    "    img_list.append(center_crop(im_array))\n",
    "    img_list.append(im_array[0:CROP_LEN,0:CROP_LEN,:])\n",
    "    img_list.append(im_array[0:CROP_LEN,512-CROP_LEN:512,:])\n",
    "    img_list.append(im_array[512-CROP_LEN:512,0:CROP_LEN,:])\n",
    "    img_list.append(im_array[512-CROP_LEN:512,512-CROP_LEN:512,:])\n",
    "    return np.array(img_list)\n",
    "tta_img = get_tta_img(test_files[0])\n",
    "print(tta_img.shape)\n",
    "tta_res = best_model.predict(tta_img)\n",
    "print(tta_res.shape)\n",
    "print(np.sum(tta_res,axis=0))\n",
    "\n",
    "test_y = []\n",
    "for img_p in test_files:\n",
    "    tmp_x = get_tta_img(img_p)\n",
    "    tmp_y = best_model.predict(tmp_x)\n",
    "    tmp_y = np.sum(tmp_y,axis=0)\n",
    "    test_y.append(tmp_y)\n",
    "\n",
    "test_y = np.array(test_y)\n",
    "print(test_y[:5])\n",
    "\n",
    "y_res = np.argmax(test_y,axis=1)\n",
    "y_res = [list_classes[i] for i in y_res]\n",
    "df = pd.read_csv('../input/sample_submission.csv')\n",
    "f_name = [p.split('/')[-1] for p in test_files]\n",
    "df['fname'] = f_name\n",
    "df['camera'] = y_res\n",
    "print(df.head())\n",
    "df.to_csv('../results/xception_manip_tta.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
