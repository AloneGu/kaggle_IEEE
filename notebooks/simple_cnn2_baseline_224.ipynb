{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Motorola-Nexus-6': [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], 'iPhone-6': [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], 'Samsung-Galaxy-Note3': [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], 'Motorola-X': [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], 'LG-Nexus-5x': [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], 'HTC-1-M7': [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], 'Sony-NEX-7': [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'iPhone-4s': [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], 'Samsung-Galaxy-S4': [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], 'Motorola-Droid-Maxx': [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "list_classes = [\n",
    " 'Sony-NEX-7',\n",
    " 'Motorola-X',\n",
    " 'HTC-1-M7',\n",
    " 'Samsung-Galaxy-Note3',\n",
    " 'Motorola-Droid-Maxx',\n",
    " 'iPhone-4s',\n",
    " 'iPhone-6',\n",
    " 'LG-Nexus-5x',\n",
    " 'Samsung-Galaxy-S4',\n",
    " 'Motorola-Nexus-6']\n",
    "\n",
    "list_dict = {}\n",
    "for i in range(10):\n",
    "    key = list_classes[i]\n",
    "    v = [0,0,0,0,0,0,0,0,0,0]\n",
    "    v[i] = 1\n",
    "    list_dict[key] = v\n",
    "print(list_dict)\n",
    "\n",
    "train_dir = '../input/train'\n",
    "test_dir = '../input/test'\n",
    "test_files = sorted(glob.glob(test_dir+'/*'))\n",
    "train_files = sorted(glob.glob(train_dir+'/*/*'))\n",
    "train_data_cnt = len(train_files)\n",
    "\n",
    "\n",
    "def get_img(img_path,crop=224,train_flag = True):\n",
    "    # read and resize\n",
    "    im_array = np.array(Image.open((img_path)), dtype=\"uint8\")\n",
    "    pil_im = Image.fromarray(im_array)\n",
    "    # new_array = np.array(pil_im.resize((512, 512)))\n",
    "    \n",
    "    # center crop\n",
    "    center_x = im_array.shape[1] // 2\n",
    "    half_crop = crop // 2\n",
    "    if train_flag:\n",
    "        rnd1 = np.random.randint(112) - 56\n",
    "        rnd2 = np.random.randint(112) - 56\n",
    "    else:\n",
    "        rnd1 = 0\n",
    "        rnd2 = 0\n",
    "    a,b = center_x + rnd1 - half_crop, center_x + rnd1 + half_crop\n",
    "    c,d = center_x + rnd2 - half_crop, center_x + rnd2 + half_crop\n",
    "    final_img = im_array[a:b,c:d,:]\n",
    "    return final_img/255.0\n",
    "\n",
    "def get_y(img_path):\n",
    "    n = img_path.split('/')[-2]\n",
    "    return list_dict[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48, 224, 224, 3) (48, 10)\n",
      "float32\n",
      "[[0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1]\n",
      " [1 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 48\n",
    "\n",
    "def data_gen(file_list, batch_size=BATCH_SIZE, train_flag = True):\n",
    "    curr_idx = 0\n",
    "    data_cnt = len(file_list)\n",
    "    while True:\n",
    "        if curr_idx + batch_size > data_cnt:\n",
    "            start_idx = data_cnt-batch_size\n",
    "            end_idx = data_cnt\n",
    "            curr_idx = 0\n",
    "        else:\n",
    "            start_idx = curr_idx\n",
    "            end_idx = curr_idx + batch_size\n",
    "            curr_idx += batch_size\n",
    "        curr_fl = file_list[start_idx:end_idx]\n",
    "        curr_x = np.array([get_img(p,224,train_flag) for p in curr_fl],dtype='float32')\n",
    "        curr_y = np.array([get_y(p) for p in curr_fl])\n",
    "        yield curr_x,curr_y\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "train_files = shuffle(train_files,random_state=42)\n",
    "\n",
    "\n",
    "train_gen = data_gen(train_files, BATCH_SIZE, True)\n",
    "valid_gen = data_gen(train_files, BATCH_SIZE, False)\n",
    "train_step = train_data_cnt//BATCH_SIZE\n",
    "valid_step = train_step\n",
    "\n",
    "# test\n",
    "for x,y in train_gen:\n",
    "    print(x.shape,y.shape)\n",
    "    print(x.dtype)\n",
    "    print(y[:3])\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 222, 222, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 111, 111, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 109, 109, 64)      18496     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 54, 54, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 27, 27, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 25, 25, 96)        55392     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 12, 12, 96)        83040     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 96)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 4, 4, 128)         110720    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 439,370\n",
      "Trainable params: 439,370\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# def model\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout, Flatten, Lambda, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint,ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "def create_model():\n",
    "    '''Create the FCN and return a keras model.'''\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3),input_shape=(224, 224, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', strides=1))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', strides=2))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(96, (3, 3), activation='relu', strides=1))\n",
    "    model.add(Conv2D(96, (3, 3), activation='relu', strides=2))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', strides=1))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    return model\n",
    "print('model model')\n",
    "tmp_m = create_model()\n",
    "tmp_m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "56/57 [============================>.] - ETA: 6s - loss: 2.2993 - acc: 0.0967 Epoch 00001: val_acc improved from -inf to 0.10490, saving model to best_cnn2_m.h5\n",
      "57/57 [==============================] - 726s 13s/step - loss: 2.2993 - acc: 0.0972 - val_loss: 2.3004 - val_acc: 0.1049\n",
      "Epoch 2/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 2.2713 - acc: 0.1321 Epoch 00002: val_acc improved from 0.10490 to 0.14547, saving model to best_cnn2_m.h5\n",
      "57/57 [==============================] - 661s 12s/step - loss: 2.2702 - acc: 0.1323 - val_loss: 2.2391 - val_acc: 0.1455\n",
      "Epoch 3/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 2.2241 - acc: 0.1518 Epoch 00003: val_acc improved from 0.14547 to 0.17398, saving model to best_cnn2_m.h5\n",
      "57/57 [==============================] - 663s 12s/step - loss: 2.2231 - acc: 0.1528 - val_loss: 2.1978 - val_acc: 0.1740\n",
      "Epoch 4/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 2.2107 - acc: 0.1633 Epoch 00004: val_acc improved from 0.17398 to 0.20249, saving model to best_cnn2_m.h5\n",
      "57/57 [==============================] - 664s 12s/step - loss: 2.2092 - acc: 0.1645 - val_loss: 2.1658 - val_acc: 0.2025\n",
      "Epoch 5/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 2.1724 - acc: 0.1875 Epoch 00005: val_acc improved from 0.20249 to 0.23538, saving model to best_cnn2_m.h5\n",
      "57/57 [==============================] - 666s 12s/step - loss: 2.1711 - acc: 0.1875 - val_loss: 2.1219 - val_acc: 0.2354\n",
      "Epoch 6/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 2.1254 - acc: 0.2076 Epoch 00006: val_acc improved from 0.23538 to 0.24561, saving model to best_cnn2_m.h5\n",
      "57/57 [==============================] - 677s 12s/step - loss: 2.1244 - acc: 0.2094 - val_loss: 2.0761 - val_acc: 0.2456\n",
      "Epoch 7/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 2.0857 - acc: 0.2314 Epoch 00007: val_acc improved from 0.24561 to 0.24671, saving model to best_cnn2_m.h5\n",
      "57/57 [==============================] - 668s 12s/step - loss: 2.0857 - acc: 0.2306 - val_loss: 2.0209 - val_acc: 0.2467\n",
      "Epoch 8/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 2.0479 - acc: 0.2422 Epoch 00008: val_acc improved from 0.24671 to 0.25841, saving model to best_cnn2_m.h5\n",
      "57/57 [==============================] - 654s 11s/step - loss: 2.0469 - acc: 0.2434 - val_loss: 1.9958 - val_acc: 0.2584\n",
      "Epoch 9/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 2.0165 - acc: 0.2630 Epoch 00009: val_acc improved from 0.25841 to 0.29386, saving model to best_cnn2_m.h5\n",
      "57/57 [==============================] - 652s 11s/step - loss: 2.0149 - acc: 0.2624 - val_loss: 1.9842 - val_acc: 0.2939\n",
      "Epoch 10/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 1.9873 - acc: 0.2738 Epoch 00010: val_acc improved from 0.29386 to 0.31287, saving model to best_cnn2_m.h5\n",
      "57/57 [==============================] - 652s 11s/step - loss: 1.9903 - acc: 0.2727 - val_loss: 1.9227 - val_acc: 0.3129\n",
      "Epoch 11/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 1.9320 - acc: 0.2980 Epoch 00011: val_acc improved from 0.31287 to 0.32420, saving model to best_cnn2_m.h5\n",
      "57/57 [==============================] - 653s 11s/step - loss: 1.9343 - acc: 0.2968 - val_loss: 1.8436 - val_acc: 0.3242\n",
      "Epoch 12/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 1.8985 - acc: 0.3006 Epoch 00012: val_acc improved from 0.32420 to 0.32858, saving model to best_cnn2_m.h5\n",
      "57/57 [==============================] - 653s 11s/step - loss: 1.9018 - acc: 0.3004 - val_loss: 1.8492 - val_acc: 0.3286\n",
      "Epoch 13/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 1.8964 - acc: 0.3043 Epoch 00013: val_acc improved from 0.32858 to 0.36623, saving model to best_cnn2_m.h5\n",
      "57/57 [==============================] - 653s 11s/step - loss: 1.8954 - acc: 0.3048 - val_loss: 1.7658 - val_acc: 0.3662\n",
      "Epoch 14/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 1.8358 - acc: 0.3281 Epoch 00014: val_acc improved from 0.36623 to 0.37500, saving model to best_cnn2_m.h5\n",
      "57/57 [==============================] - 652s 11s/step - loss: 1.8354 - acc: 0.3282 - val_loss: 1.7419 - val_acc: 0.3750\n",
      "Epoch 15/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 1.8103 - acc: 0.3486 Epoch 00015: val_acc did not improve\n",
      "57/57 [==============================] - 653s 11s/step - loss: 1.8092 - acc: 0.3498 - val_loss: 1.8106 - val_acc: 0.3542\n",
      "Epoch 16/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 1.7774 - acc: 0.3583 Epoch 00016: val_acc did not improve\n",
      "57/57 [==============================] - 648s 11s/step - loss: 1.7762 - acc: 0.3571 - val_loss: 1.8033 - val_acc: 0.3286\n",
      "Epoch 17/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 1.7063 - acc: 0.3795 Epoch 00017: val_acc improved from 0.37500 to 0.40753, saving model to best_cnn2_m.h5\n",
      "57/57 [==============================] - 649s 11s/step - loss: 1.7069 - acc: 0.3798 - val_loss: 1.6875 - val_acc: 0.4075\n",
      "Epoch 18/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 1.6694 - acc: 0.3906 Epoch 00018: val_acc did not improve\n",
      "57/57 [==============================] - 652s 11s/step - loss: 1.6712 - acc: 0.3900 - val_loss: 1.6622 - val_acc: 0.4020\n",
      "Epoch 19/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 1.6186 - acc: 0.4059 Epoch 00019: val_acc improved from 0.40753 to 0.43421, saving model to best_cnn2_m.h5\n",
      "57/57 [==============================] - 650s 11s/step - loss: 1.6188 - acc: 0.4068 - val_loss: 1.5663 - val_acc: 0.4342\n",
      "Epoch 20/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 1.5790 - acc: 0.4282 Epoch 00020: val_acc improved from 0.43421 to 0.47368, saving model to best_cnn2_m.h5\n",
      "57/57 [==============================] - 653s 11s/step - loss: 1.5787 - acc: 0.4287 - val_loss: 1.4887 - val_acc: 0.4737\n",
      "Epoch 21/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 1.5606 - acc: 0.4379 Epoch 00021: val_acc improved from 0.47368 to 0.47917, saving model to best_cnn2_m.h5\n",
      "57/57 [==============================] - 654s 11s/step - loss: 1.5591 - acc: 0.4393 - val_loss: 1.4494 - val_acc: 0.4792\n",
      "Epoch 22/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 1.5188 - acc: 0.4494 Epoch 00022: val_acc improved from 0.47917 to 0.47990, saving model to best_cnn2_m.h5\n",
      "57/57 [==============================] - 654s 11s/step - loss: 1.5200 - acc: 0.4481 - val_loss: 1.4605 - val_acc: 0.4799\n",
      "Epoch 23/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 1.4711 - acc: 0.4635 Epoch 00023: val_acc did not improve\n",
      "57/57 [==============================] - 653s 11s/step - loss: 1.4731 - acc: 0.4624 - val_loss: 1.6090 - val_acc: 0.4200\n",
      "Epoch 24/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 1.4651 - acc: 0.4758 Epoch 00024: val_acc improved from 0.47990 to 0.48355, saving model to best_cnn2_m.h5\n",
      "57/57 [==============================] - 652s 11s/step - loss: 1.4693 - acc: 0.4733 - val_loss: 1.4532 - val_acc: 0.4836\n",
      "Epoch 25/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 1.4634 - acc: 0.4762 Epoch 00025: val_acc improved from 0.48355 to 0.48904, saving model to best_cnn2_m.h5\n",
      "57/57 [==============================] - 651s 11s/step - loss: 1.4593 - acc: 0.4784 - val_loss: 1.4330 - val_acc: 0.4890\n",
      "Epoch 26/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 1.4232 - acc: 0.4940 Epoch 00026: val_acc improved from 0.48904 to 0.50475, saving model to best_cnn2_m.h5\n",
      "57/57 [==============================] - 652s 11s/step - loss: 1.4231 - acc: 0.4927 - val_loss: 1.3527 - val_acc: 0.5048\n",
      "Epoch 27/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 1.3593 - acc: 0.5074 Epoch 00027: val_acc improved from 0.50475 to 0.53436, saving model to best_cnn2_m.h5\n",
      "57/57 [==============================] - 651s 11s/step - loss: 1.3586 - acc: 0.5084 - val_loss: 1.2988 - val_acc: 0.5344\n",
      "Epoch 28/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 1.3548 - acc: 0.5216 Epoch 00028: val_acc improved from 0.53436 to 0.55738, saving model to best_cnn2_m.h5\n",
      "57/57 [==============================] - 650s 11s/step - loss: 1.3547 - acc: 0.5219 - val_loss: 1.2326 - val_acc: 0.5574\n",
      "Epoch 29/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 1.2853 - acc: 0.5413 Epoch 00029: val_acc improved from 0.55738 to 0.56506, saving model to best_cnn2_m.h5\n",
      "57/57 [==============================] - 652s 11s/step - loss: 1.2872 - acc: 0.5402 - val_loss: 1.2099 - val_acc: 0.5651\n",
      "Epoch 30/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 1.2900 - acc: 0.5353 Epoch 00030: val_acc did not improve\n",
      "57/57 [==============================] - 651s 11s/step - loss: 1.2876 - acc: 0.5358 - val_loss: 1.2420 - val_acc: 0.5545\n",
      "Epoch 31/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 1.2737 - acc: 0.5428Epoch 00031: val_acc did not improve\n",
      "57/57 [==============================] - 649s 11s/step - loss: 1.2693 - acc: 0.5442 - val_loss: 1.2390 - val_acc: 0.5523\n",
      "Epoch 32/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 1.2579 - acc: 0.5424 Epoch 00032: val_acc improved from 0.56506 to 0.58041, saving model to best_cnn2_m.h5\n",
      "57/57 [==============================] - 649s 11s/step - loss: 1.2631 - acc: 0.5402 - val_loss: 1.1645 - val_acc: 0.5804\n",
      "Epoch 33/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 1.2440 - acc: 0.5610 Epoch 00033: val_acc improved from 0.58041 to 0.61988, saving model to best_cnn2_m.h5\n",
      "57/57 [==============================] - 650s 11s/step - loss: 1.2440 - acc: 0.5596 - val_loss: 1.0837 - val_acc: 0.6199\n",
      "Epoch 34/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 1.1760 - acc: 0.5837Epoch 00034: val_acc did not improve\n",
      "57/57 [==============================] - 650s 11s/step - loss: 1.1773 - acc: 0.5826 - val_loss: 1.1331 - val_acc: 0.6023\n",
      "Epoch 35/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 1.2123 - acc: 0.5692 Epoch 00035: val_acc did not improve\n",
      "57/57 [==============================] - 650s 11s/step - loss: 1.2074 - acc: 0.5709 - val_loss: 1.1174 - val_acc: 0.6020\n",
      "Epoch 36/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 1.1650 - acc: 0.5796 Epoch 00036: val_acc did not improve\n",
      "57/57 [==============================] - 652s 11s/step - loss: 1.1638 - acc: 0.5808 - val_loss: 1.0683 - val_acc: 0.6151\n",
      "Epoch 37/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 1.1809 - acc: 0.5766 Epoch 00037: val_acc improved from 0.61988 to 0.63889, saving model to best_cnn2_m.h5\n",
      "57/57 [==============================] - 651s 11s/step - loss: 1.1791 - acc: 0.5771 - val_loss: 1.0142 - val_acc: 0.6389\n",
      "Epoch 38/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 1.1140 - acc: 0.6094Epoch 00038: val_acc improved from 0.63889 to 0.63889, saving model to best_cnn2_m.h5\n",
      "57/57 [==============================] - 649s 11s/step - loss: 1.1154 - acc: 0.6078 - val_loss: 1.0134 - val_acc: 0.6389\n",
      "Epoch 39/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 1.0978 - acc: 0.6023Epoch 00039: val_acc improved from 0.63889 to 0.65826, saving model to best_cnn2_m.h5\n",
      "57/57 [==============================] - 649s 11s/step - loss: 1.0990 - acc: 0.6012 - val_loss: 0.9855 - val_acc: 0.6583\n",
      "Epoch 40/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 1.0894 - acc: 0.6109Epoch 00040: val_acc did not improve\n",
      "57/57 [==============================] - 649s 11s/step - loss: 1.0897 - acc: 0.6100 - val_loss: 0.9766 - val_acc: 0.6480\n",
      "Epoch 41/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 1.0848 - acc: 0.6131 Epoch 00041: val_acc did not improve\n",
      "57/57 [==============================] - 648s 11s/step - loss: 1.0859 - acc: 0.6118 - val_loss: 0.9963 - val_acc: 0.6477\n",
      "Epoch 42/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 1.0383 - acc: 0.6321 Epoch 00042: val_acc improved from 0.65826 to 0.65899, saving model to best_cnn2_m.h5\n",
      "57/57 [==============================] - 649s 11s/step - loss: 1.0349 - acc: 0.6330 - val_loss: 0.9694 - val_acc: 0.6590\n",
      "Epoch 43/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.9864 - acc: 0.6462 Epoch 00043: val_acc improved from 0.65899 to 0.66447, saving model to best_cnn2_m.h5\n",
      "57/57 [==============================] - 651s 11s/step - loss: 0.9869 - acc: 0.6462 - val_loss: 0.9421 - val_acc: 0.6645\n",
      "Epoch 44/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 1.0360 - acc: 0.6321Epoch 00044: val_acc improved from 0.66447 to 0.68823, saving model to best_cnn2_m.h5\n",
      "57/57 [==============================] - 648s 11s/step - loss: 1.0347 - acc: 0.6327 - val_loss: 0.8855 - val_acc: 0.6882\n",
      "Epoch 45/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.9943 - acc: 0.6503 Epoch 00045: val_acc improved from 0.68823 to 0.71016, saving model to best_cnn2_m.h5\n",
      "57/57 [==============================] - 651s 11s/step - loss: 0.9936 - acc: 0.6513 - val_loss: 0.8499 - val_acc: 0.7102\n",
      "Epoch 46/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.9927 - acc: 0.6462 Epoch 00046: val_acc did not improve\n",
      "57/57 [==============================] - 649s 11s/step - loss: 0.9873 - acc: 0.6477 - val_loss: 0.9221 - val_acc: 0.6725\n",
      "Epoch 47/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 1.0248 - acc: 0.6373 Epoch 00047: val_acc did not improve\n",
      "57/57 [==============================] - 650s 11s/step - loss: 1.0285 - acc: 0.6356 - val_loss: 0.8716 - val_acc: 0.6893\n",
      "Epoch 48/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.9208 - acc: 0.6734 Epoch 00048: val_acc did not improve\n",
      "57/57 [==============================] - 648s 11s/step - loss: 0.9228 - acc: 0.6718 - val_loss: 0.9469 - val_acc: 0.6721\n",
      "Epoch 49/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.9575 - acc: 0.6700 Epoch 00049: val_acc improved from 0.71016 to 0.71382, saving model to best_cnn2_m.h5\n",
      "57/57 [==============================] - 649s 11s/step - loss: 0.9539 - acc: 0.6707 - val_loss: 0.8239 - val_acc: 0.7138\n",
      "Epoch 50/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.9269 - acc: 0.6555 Epoch 00050: val_acc did not improve\n",
      "57/57 [==============================] - 649s 11s/step - loss: 0.9313 - acc: 0.6520 - val_loss: 0.8486 - val_acc: 0.6937\n",
      "Epoch 51/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.9287 - acc: 0.6771 Epoch 00051: val_acc did not improve\n",
      "57/57 [==============================] - 650s 11s/step - loss: 0.9248 - acc: 0.6798 - val_loss: 0.8279 - val_acc: 0.7076\n",
      "Epoch 52/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.9309 - acc: 0.6715 Epoch 00052: val_acc did not improve\n",
      "57/57 [==============================] - 651s 11s/step - loss: 0.9310 - acc: 0.6714 - val_loss: 0.8246 - val_acc: 0.7054\n",
      "Epoch 53/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.9222 - acc: 0.6830 Epoch 00053: val_acc improved from 0.71382 to 0.72149, saving model to best_cnn2_m.h5\n",
      "57/57 [==============================] - 651s 11s/step - loss: 0.9159 - acc: 0.6857 - val_loss: 0.7914 - val_acc: 0.7215\n",
      "Epoch 54/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.8864 - acc: 0.6804 Epoch 00054: val_acc improved from 0.72149 to 0.72697, saving model to best_cnn2_m.h5\n",
      "57/57 [==============================] - 650s 11s/step - loss: 0.8848 - acc: 0.6802 - val_loss: 0.7599 - val_acc: 0.7270\n",
      "Epoch 55/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.8456 - acc: 0.7087 Epoch 00055: val_acc did not improve\n",
      "57/57 [==============================] - 649s 11s/step - loss: 0.8445 - acc: 0.7098 - val_loss: 0.7769 - val_acc: 0.7211\n",
      "Epoch 56/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.8509 - acc: 0.6975 Epoch 00056: val_acc improved from 0.72697 to 0.74488, saving model to best_cnn2_m.h5\n",
      "57/57 [==============================] - 650s 11s/step - loss: 0.8525 - acc: 0.6966 - val_loss: 0.7277 - val_acc: 0.7449\n",
      "Epoch 57/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.8779 - acc: 0.6856 Epoch 00057: val_acc did not improve\n",
      "57/57 [==============================] - 648s 11s/step - loss: 0.8755 - acc: 0.6860 - val_loss: 0.7492 - val_acc: 0.7434\n",
      "Epoch 58/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.8683 - acc: 0.6931 Epoch 00058: val_acc did not improve\n",
      "57/57 [==============================] - 651s 11s/step - loss: 0.8661 - acc: 0.6948 - val_loss: 0.7464 - val_acc: 0.7379\n",
      "Epoch 59/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/57 [============================>.] - ETA: 5s - loss: 0.8267 - acc: 0.7150 Epoch 00059: val_acc did not improve\n",
      "57/57 [==============================] - 650s 11s/step - loss: 0.8223 - acc: 0.7175 - val_loss: 0.7479 - val_acc: 0.7368\n",
      "Epoch 60/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.8267 - acc: 0.7191 Epoch 00060: val_acc did not improve\n",
      "57/57 [==============================] - 649s 11s/step - loss: 0.8284 - acc: 0.7193 - val_loss: 0.8465 - val_acc: 0.7029\n",
      "Epoch 61/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.7497 - acc: 0.7388 Epoch 00061: val_acc improved from 0.74488 to 0.76937, saving model to best_cnn2_m.h5\n",
      "57/57 [==============================] - 650s 11s/step - loss: 0.7483 - acc: 0.7390 - val_loss: 0.6368 - val_acc: 0.7694\n",
      "Epoch 62/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.6996 - acc: 0.7563 Epoch 00062: val_acc improved from 0.76937 to 0.78289, saving model to best_cnn2_m.h5\n",
      "57/57 [==============================] - 647s 11s/step - loss: 0.6983 - acc: 0.7566 - val_loss: 0.6239 - val_acc: 0.7829\n",
      "Epoch 63/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.6936 - acc: 0.7463 Epoch 00063: val_acc improved from 0.78289 to 0.79532, saving model to best_cnn2_m.h5\n",
      "57/57 [==============================] - 651s 11s/step - loss: 0.6962 - acc: 0.7471 - val_loss: 0.5956 - val_acc: 0.7953\n",
      "Epoch 64/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.7067 - acc: 0.7504 Epoch 00064: val_acc did not improve\n",
      "57/57 [==============================] - 649s 11s/step - loss: 0.7080 - acc: 0.7489 - val_loss: 0.6142 - val_acc: 0.7792\n",
      "Epoch 65/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.6413 - acc: 0.7790 Epoch 00065: val_acc improved from 0.79532 to 0.81031, saving model to best_cnn2_m.h5\n",
      "57/57 [==============================] - 651s 11s/step - loss: 0.6453 - acc: 0.7785 - val_loss: 0.5474 - val_acc: 0.8103\n",
      "Epoch 66/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.6231 - acc: 0.7731 Epoch 00066: val_acc did not improve\n",
      "57/57 [==============================] - 651s 11s/step - loss: 0.6232 - acc: 0.7734 - val_loss: 0.5694 - val_acc: 0.8015\n",
      "Epoch 67/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.6765 - acc: 0.7656 Epoch 00067: val_acc did not improve\n",
      "57/57 [==============================] - 649s 11s/step - loss: 0.6748 - acc: 0.7661 - val_loss: 0.5718 - val_acc: 0.7979\n",
      "Epoch 68/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.6469 - acc: 0.7697 Epoch 00068: val_acc improved from 0.81031 to 0.82493, saving model to best_cnn2_m.h5\n",
      "57/57 [==============================] - 650s 11s/step - loss: 0.6507 - acc: 0.7683 - val_loss: 0.5262 - val_acc: 0.8249\n",
      "Epoch 69/150\n",
      "56/57 [============================>.] - ETA: 4s - loss: 0.6413 - acc: 0.7775Epoch 00069: val_acc did not improve\n",
      "57/57 [==============================] - 645s 11s/step - loss: 0.6434 - acc: 0.7767 - val_loss: 0.5572 - val_acc: 0.8125\n",
      "Epoch 70/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.5981 - acc: 0.7932 Epoch 00070: val_acc did not improve\n",
      "57/57 [==============================] - 652s 11s/step - loss: 0.5983 - acc: 0.7928 - val_loss: 0.5327 - val_acc: 0.8173\n",
      "Epoch 71/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.5985 - acc: 0.7891 Epoch 00071: val_acc did not improve\n",
      "57/57 [==============================] - 652s 11s/step - loss: 0.5995 - acc: 0.7891 - val_loss: 0.5218 - val_acc: 0.8191\n",
      "Epoch 72/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.6301 - acc: 0.7794 Epoch 00072: val_acc did not improve\n",
      "57/57 [==============================] - 649s 11s/step - loss: 0.6263 - acc: 0.7803 - val_loss: 0.5316 - val_acc: 0.8165\n",
      "Epoch 73/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.5601 - acc: 0.7999 Epoch 00073: val_acc improved from 0.82493 to 0.84539, saving model to best_cnn2_m.h5\n",
      "57/57 [==============================] - 651s 11s/step - loss: 0.5642 - acc: 0.7975 - val_loss: 0.4443 - val_acc: 0.8454\n",
      "Epoch 74/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.5173 - acc: 0.8244 Epoch 00074: val_acc improved from 0.84539 to 0.85197, saving model to best_cnn2_m.h5\n",
      "57/57 [==============================] - 651s 11s/step - loss: 0.5174 - acc: 0.8246 - val_loss: 0.4227 - val_acc: 0.8520\n",
      "Epoch 75/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.5024 - acc: 0.8311 Epoch 00075: val_acc improved from 0.85197 to 0.85965, saving model to best_cnn2_m.h5\n",
      "57/57 [==============================] - 652s 11s/step - loss: 0.5082 - acc: 0.8297 - val_loss: 0.4108 - val_acc: 0.8596\n",
      "Epoch 76/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.4954 - acc: 0.8292 Epoch 00076: val_acc did not improve\n",
      "57/57 [==============================] - 649s 11s/step - loss: 0.5001 - acc: 0.8264 - val_loss: 0.4466 - val_acc: 0.8428\n",
      "Epoch 77/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.5219 - acc: 0.8211 Epoch 00077: val_acc did not improve\n",
      "57/57 [==============================] - 652s 11s/step - loss: 0.5286 - acc: 0.8191 - val_loss: 0.4159 - val_acc: 0.8545\n",
      "Epoch 78/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.4820 - acc: 0.8344 Epoch 00078: val_acc did not improve\n",
      "57/57 [==============================] - 652s 11s/step - loss: 0.4802 - acc: 0.8352 - val_loss: 0.4228 - val_acc: 0.8505\n",
      "Epoch 79/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.5198 - acc: 0.8218 Epoch 00079: val_acc improved from 0.85965 to 0.86696, saving model to best_cnn2_m.h5\n",
      "57/57 [==============================] - 650s 11s/step - loss: 0.5184 - acc: 0.8216 - val_loss: 0.3938 - val_acc: 0.8670\n",
      "Epoch 80/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.4631 - acc: 0.8367 Epoch 00080: val_acc improved from 0.86696 to 0.87354, saving model to best_cnn2_m.h5\n",
      "57/57 [==============================] - 652s 11s/step - loss: 0.4617 - acc: 0.8381 - val_loss: 0.3850 - val_acc: 0.8735\n",
      "Epoch 81/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.4847 - acc: 0.8326 Epoch 00081: val_acc improved from 0.87354 to 0.87573, saving model to best_cnn2_m.h5\n",
      "57/57 [==============================] - 651s 11s/step - loss: 0.4847 - acc: 0.8322 - val_loss: 0.3795 - val_acc: 0.8757\n",
      "Epoch 82/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.4815 - acc: 0.8337 Epoch 00082: val_acc did not improve\n",
      "57/57 [==============================] - 647s 11s/step - loss: 0.4794 - acc: 0.8348 - val_loss: 0.3750 - val_acc: 0.8692\n",
      "Epoch 83/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.4489 - acc: 0.8478 Epoch 00083: val_acc improved from 0.87573 to 0.87866, saving model to best_cnn2_m.h5\n",
      "57/57 [==============================] - 651s 11s/step - loss: 0.4473 - acc: 0.8472 - val_loss: 0.3576 - val_acc: 0.8787\n",
      "Epoch 84/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.4863 - acc: 0.8341 Epoch 00084: val_acc did not improve\n",
      "57/57 [==============================] - 651s 11s/step - loss: 0.4890 - acc: 0.8337 - val_loss: 0.3677 - val_acc: 0.8787\n",
      "Epoch 85/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.4714 - acc: 0.8237 Epoch 00085: val_acc did not improve\n",
      "57/57 [==============================] - 652s 11s/step - loss: 0.4693 - acc: 0.8246 - val_loss: 0.3593 - val_acc: 0.8768\n",
      "Epoch 86/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.4449 - acc: 0.8430 Epoch 00086: val_acc improved from 0.87866 to 0.88268, saving model to best_cnn2_m.h5\n",
      "57/57 [==============================] - 647s 11s/step - loss: 0.4463 - acc: 0.8428 - val_loss: 0.3574 - val_acc: 0.8827\n",
      "Epoch 87/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.4642 - acc: 0.8423Epoch 00087: val_acc did not improve\n",
      "57/57 [==============================] - 649s 11s/step - loss: 0.4625 - acc: 0.8425 - val_loss: 0.3707 - val_acc: 0.8702\n",
      "Epoch 88/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.4468 - acc: 0.8411Epoch 00088: val_acc did not improve\n",
      "57/57 [==============================] - 647s 11s/step - loss: 0.4448 - acc: 0.8421 - val_loss: 0.3476 - val_acc: 0.8823\n",
      "Epoch 89/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.4318 - acc: 0.8501Epoch 00089: val_acc improved from 0.88268 to 0.88816, saving model to best_cnn2_m.h5\n",
      "57/57 [==============================] - 644s 11s/step - loss: 0.4294 - acc: 0.8512 - val_loss: 0.3292 - val_acc: 0.8882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.4219 - acc: 0.8508 Epoch 00090: val_acc did not improve\n",
      "57/57 [==============================] - 645s 11s/step - loss: 0.4239 - acc: 0.8505 - val_loss: 0.3616 - val_acc: 0.8801\n",
      "Epoch 91/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.4197 - acc: 0.8594Epoch 00091: val_acc did not improve\n",
      "57/57 [==============================] - 645s 11s/step - loss: 0.4216 - acc: 0.8596 - val_loss: 0.3453 - val_acc: 0.8852\n",
      "Epoch 92/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.4383 - acc: 0.8438Epoch 00092: val_acc did not improve\n",
      "57/57 [==============================] - 647s 11s/step - loss: 0.4405 - acc: 0.8443 - val_loss: 0.3512 - val_acc: 0.8845\n",
      "Epoch 93/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.4221 - acc: 0.8523Epoch 00093: val_acc did not improve\n",
      "57/57 [==============================] - 646s 11s/step - loss: 0.4213 - acc: 0.8520 - val_loss: 0.3477 - val_acc: 0.8867\n",
      "Epoch 94/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.4013 - acc: 0.8624Epoch 00094: val_acc improved from 0.88816 to 0.89510, saving model to best_cnn2_m.h5\n",
      "57/57 [==============================] - 650s 11s/step - loss: 0.4018 - acc: 0.8626 - val_loss: 0.3152 - val_acc: 0.8951\n",
      "Epoch 95/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.3582 - acc: 0.8780Epoch 00095: val_acc improved from 0.89510 to 0.89766, saving model to best_cnn2_m.h5\n",
      "57/57 [==============================] - 649s 11s/step - loss: 0.3564 - acc: 0.8790 - val_loss: 0.3042 - val_acc: 0.8977\n",
      "Epoch 96/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.3716 - acc: 0.8772Epoch 00096: val_acc improved from 0.89766 to 0.89839, saving model to best_cnn2_m.h5\n",
      "57/57 [==============================] - 648s 11s/step - loss: 0.3727 - acc: 0.8768 - val_loss: 0.2988 - val_acc: 0.8984\n",
      "Epoch 97/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.4017 - acc: 0.8612Epoch 00097: val_acc did not improve\n",
      "57/57 [==============================] - 650s 11s/step - loss: 0.4016 - acc: 0.8604 - val_loss: 0.3064 - val_acc: 0.8980\n",
      "Epoch 98/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.3768 - acc: 0.8731Epoch 00098: val_acc did not improve\n",
      "57/57 [==============================] - 648s 11s/step - loss: 0.3763 - acc: 0.8728 - val_loss: 0.3039 - val_acc: 0.8980\n",
      "Epoch 99/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.3725 - acc: 0.8761Epoch 00099: val_acc improved from 0.89839 to 0.90351, saving model to best_cnn2_m.h5\n",
      "57/57 [==============================] - 649s 11s/step - loss: 0.3722 - acc: 0.8761 - val_loss: 0.2950 - val_acc: 0.9035\n",
      "Epoch 100/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.3802 - acc: 0.8687 Epoch 00100: val_acc did not improve\n",
      "57/57 [==============================] - 650s 11s/step - loss: 0.3765 - acc: 0.8706 - val_loss: 0.3124 - val_acc: 0.8955\n",
      "Epoch 101/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.3788 - acc: 0.8683Epoch 00101: val_acc improved from 0.90351 to 0.90789, saving model to best_cnn2_m.h5\n",
      "57/57 [==============================] - 650s 11s/step - loss: 0.3774 - acc: 0.8681 - val_loss: 0.2810 - val_acc: 0.9079\n",
      "Epoch 102/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.3746 - acc: 0.8672 Epoch 00102: val_acc did not improve\n",
      "57/57 [==============================] - 649s 11s/step - loss: 0.3731 - acc: 0.8673 - val_loss: 0.2782 - val_acc: 0.9061\n",
      "Epoch 103/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.3551 - acc: 0.8690Epoch 00103: val_acc did not improve\n",
      "57/57 [==============================] - 647s 11s/step - loss: 0.3553 - acc: 0.8695 - val_loss: 0.2871 - val_acc: 0.9057\n",
      "Epoch 104/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.3579 - acc: 0.8735 Epoch 00104: val_acc improved from 0.90789 to 0.91045, saving model to best_cnn2_m.h5\n",
      "57/57 [==============================] - 645s 11s/step - loss: 0.3543 - acc: 0.8743 - val_loss: 0.2779 - val_acc: 0.9105\n",
      "Epoch 105/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.3623 - acc: 0.8709 Epoch 00105: val_acc improved from 0.91045 to 0.91045, saving model to best_cnn2_m.h5\n",
      "57/57 [==============================] - 648s 11s/step - loss: 0.3657 - acc: 0.8702 - val_loss: 0.2731 - val_acc: 0.9105\n",
      "Epoch 106/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.3479 - acc: 0.8821 Epoch 00106: val_acc did not improve\n",
      "57/57 [==============================] - 650s 11s/step - loss: 0.3469 - acc: 0.8823 - val_loss: 0.2744 - val_acc: 0.9079\n",
      "Epoch 107/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.3574 - acc: 0.8728 Epoch 00107: val_acc did not improve\n",
      "57/57 [==============================] - 649s 11s/step - loss: 0.3562 - acc: 0.8735 - val_loss: 0.2744 - val_acc: 0.9064\n",
      "Epoch 108/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.3581 - acc: 0.8798 Epoch 00108: val_acc improved from 0.91045 to 0.91155, saving model to best_cnn2_m.h5\n",
      "57/57 [==============================] - 649s 11s/step - loss: 0.3569 - acc: 0.8805 - val_loss: 0.2699 - val_acc: 0.9115\n",
      "Epoch 109/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.3212 - acc: 0.8917 Epoch 00109: val_acc improved from 0.91155 to 0.91630, saving model to best_cnn2_m.h5\n",
      "57/57 [==============================] - 650s 11s/step - loss: 0.3212 - acc: 0.8918 - val_loss: 0.2593 - val_acc: 0.9163\n",
      "Epoch 110/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.3436 - acc: 0.8847 Epoch 00110: val_acc did not improve\n",
      "57/57 [==============================] - 651s 11s/step - loss: 0.3439 - acc: 0.8841 - val_loss: 0.2605 - val_acc: 0.9126\n",
      "Epoch 111/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.3466 - acc: 0.8832 Epoch 00111: val_acc did not improve\n",
      "57/57 [==============================] - 651s 11s/step - loss: 0.3456 - acc: 0.8834 - val_loss: 0.2664 - val_acc: 0.9086\n",
      "Epoch 112/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.3603 - acc: 0.8761 Epoch 00112: val_acc did not improve\n",
      "57/57 [==============================] - 651s 11s/step - loss: 0.3585 - acc: 0.8761 - val_loss: 0.2723 - val_acc: 0.9083\n",
      "Epoch 113/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.3540 - acc: 0.8806 Epoch 00113: val_acc did not improve\n",
      "57/57 [==============================] - 650s 11s/step - loss: 0.3527 - acc: 0.8812 - val_loss: 0.2559 - val_acc: 0.9115\n",
      "Epoch 114/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.3084 - acc: 0.8955 Epoch 00114: val_acc improved from 0.91630 to 0.92251, saving model to best_cnn2_m.h5\n",
      "57/57 [==============================] - 651s 11s/step - loss: 0.3079 - acc: 0.8955 - val_loss: 0.2449 - val_acc: 0.9225\n",
      "Epoch 115/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.3099 - acc: 0.8962 Epoch 00115: val_acc did not improve\n",
      "57/57 [==============================] - 651s 11s/step - loss: 0.3069 - acc: 0.8973 - val_loss: 0.2506 - val_acc: 0.9185\n",
      "Epoch 116/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.3301 - acc: 0.8884 Epoch 00116: val_acc did not improve\n",
      "57/57 [==============================] - 650s 11s/step - loss: 0.3281 - acc: 0.8889 - val_loss: 0.2455 - val_acc: 0.9214\n",
      "Epoch 117/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.3116 - acc: 0.8899 Epoch 00117: val_acc did not improve\n",
      "57/57 [==============================] - 651s 11s/step - loss: 0.3096 - acc: 0.8907 - val_loss: 0.2471 - val_acc: 0.9221\n",
      "Epoch 118/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.3223 - acc: 0.8921 Epoch 00118: val_acc did not improve\n",
      "57/57 [==============================] - 650s 11s/step - loss: 0.3199 - acc: 0.8933 - val_loss: 0.2427 - val_acc: 0.9192\n",
      "Epoch 119/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.3120 - acc: 0.8903 Epoch 00119: val_acc did not improve\n",
      "57/57 [==============================] - 649s 11s/step - loss: 0.3143 - acc: 0.8900 - val_loss: 0.2412 - val_acc: 0.9225\n",
      "Epoch 120/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.3004 - acc: 0.8966 Epoch 00120: val_acc improved from 0.92251 to 0.92471, saving model to best_cnn2_m.h5\n",
      "57/57 [==============================] - 649s 11s/step - loss: 0.3026 - acc: 0.8951 - val_loss: 0.2398 - val_acc: 0.9247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.3147 - acc: 0.8865 Epoch 00121: val_acc improved from 0.92471 to 0.92544, saving model to best_cnn2_m.h5\n",
      "57/57 [==============================] - 651s 11s/step - loss: 0.3137 - acc: 0.8871 - val_loss: 0.2373 - val_acc: 0.9254\n",
      "Epoch 122/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.3053 - acc: 0.8977 Epoch 00122: val_acc did not improve\n",
      "57/57 [==============================] - 649s 11s/step - loss: 0.3065 - acc: 0.8980 - val_loss: 0.2388 - val_acc: 0.9251\n",
      "Epoch 123/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.2981 - acc: 0.9051 Epoch 00123: val_acc did not improve\n",
      "57/57 [==============================] - 645s 11s/step - loss: 0.2999 - acc: 0.9046 - val_loss: 0.2380 - val_acc: 0.9207\n",
      "Epoch 124/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.3032 - acc: 0.8988 Epoch 00124: val_acc improved from 0.92544 to 0.92617, saving model to best_cnn2_m.h5\n",
      "57/57 [==============================] - 649s 11s/step - loss: 0.3003 - acc: 0.8999 - val_loss: 0.2337 - val_acc: 0.9262\n",
      "Epoch 125/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.2979 - acc: 0.8921 Epoch 00125: val_acc did not improve\n",
      "57/57 [==============================] - 650s 11s/step - loss: 0.2949 - acc: 0.8936 - val_loss: 0.2340 - val_acc: 0.9221\n",
      "Epoch 126/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.3020 - acc: 0.8958 Epoch 00126: val_acc did not improve\n",
      "57/57 [==============================] - 651s 11s/step - loss: 0.3052 - acc: 0.8944 - val_loss: 0.2324 - val_acc: 0.9254\n",
      "Epoch 127/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.2974 - acc: 0.9025 Epoch 00127: val_acc improved from 0.92617 to 0.92763, saving model to best_cnn2_m.h5\n",
      "57/57 [==============================] - 648s 11s/step - loss: 0.3025 - acc: 0.9002 - val_loss: 0.2322 - val_acc: 0.9276\n",
      "Epoch 128/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.2983 - acc: 0.8940 Epoch 00128: val_acc did not improve\n",
      "57/57 [==============================] - 650s 11s/step - loss: 0.2981 - acc: 0.8936 - val_loss: 0.2340 - val_acc: 0.9254\n",
      "Epoch 129/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.3023 - acc: 0.8951 Epoch 00129: val_acc improved from 0.92763 to 0.92800, saving model to best_cnn2_m.h5\n",
      "57/57 [==============================] - 653s 11s/step - loss: 0.3023 - acc: 0.8951 - val_loss: 0.2298 - val_acc: 0.9280\n",
      "Epoch 130/150\n",
      "56/57 [============================>.] - ETA: 4s - loss: 0.3219 - acc: 0.8914Epoch 00130: val_acc did not improve\n",
      "57/57 [==============================] - 643s 11s/step - loss: 0.3191 - acc: 0.8922 - val_loss: 0.2308 - val_acc: 0.9258\n",
      "Epoch 131/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.2797 - acc: 0.9025 Epoch 00131: val_acc improved from 0.92800 to 0.92982, saving model to best_cnn2_m.h5\n",
      "57/57 [==============================] - 650s 11s/step - loss: 0.2841 - acc: 0.9006 - val_loss: 0.2270 - val_acc: 0.9298\n",
      "Epoch 132/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.3047 - acc: 0.8903 Epoch 00132: val_acc improved from 0.92982 to 0.92982, saving model to best_cnn2_m.h5\n",
      "57/57 [==============================] - 650s 11s/step - loss: 0.3040 - acc: 0.8896 - val_loss: 0.2258 - val_acc: 0.9298\n",
      "Epoch 133/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.2843 - acc: 0.9007 Epoch 00133: val_acc did not improve\n",
      "57/57 [==============================] - 652s 11s/step - loss: 0.2870 - acc: 0.8995 - val_loss: 0.2277 - val_acc: 0.9269\n",
      "Epoch 134/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.2853 - acc: 0.9033 Epoch 00134: val_acc improved from 0.92982 to 0.93019, saving model to best_cnn2_m.h5\n",
      "57/57 [==============================] - 654s 11s/step - loss: 0.2881 - acc: 0.9020 - val_loss: 0.2259 - val_acc: 0.9302\n",
      "Epoch 135/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.2938 - acc: 0.9007 Epoch 00135: val_acc did not improve\n",
      "57/57 [==============================] - 652s 11s/step - loss: 0.2961 - acc: 0.9002 - val_loss: 0.2283 - val_acc: 0.9295\n",
      "Epoch 136/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.2973 - acc: 0.8910 Epoch 00136: val_acc did not improve\n",
      "57/57 [==============================] - 653s 11s/step - loss: 0.2963 - acc: 0.8918 - val_loss: 0.2258 - val_acc: 0.9284\n",
      "Epoch 137/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.2924 - acc: 0.8988 Epoch 00137: val_acc did not improve\n",
      "57/57 [==============================] - 652s 11s/step - loss: 0.2917 - acc: 0.8991 - val_loss: 0.2238 - val_acc: 0.9295\n",
      "Epoch 138/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.2829 - acc: 0.9036 Epoch 00138: val_acc improved from 0.93019 to 0.93238, saving model to best_cnn2_m.h5\n",
      "57/57 [==============================] - 652s 11s/step - loss: 0.2834 - acc: 0.9031 - val_loss: 0.2210 - val_acc: 0.9324\n",
      "Epoch 139/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.2932 - acc: 0.8969 Epoch 00139: val_acc did not improve\n",
      "57/57 [==============================] - 653s 11s/step - loss: 0.2954 - acc: 0.8962 - val_loss: 0.2197 - val_acc: 0.9324\n",
      "Epoch 140/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.2888 - acc: 0.9018 Epoch 00140: val_acc did not improve\n",
      "57/57 [==============================] - 653s 11s/step - loss: 0.2880 - acc: 0.9024 - val_loss: 0.2223 - val_acc: 0.9291\n",
      "Epoch 141/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.2848 - acc: 0.9055 Epoch 00141: val_acc improved from 0.93238 to 0.93421, saving model to best_cnn2_m.h5\n",
      "57/57 [==============================] - 651s 11s/step - loss: 0.2825 - acc: 0.9061 - val_loss: 0.2197 - val_acc: 0.9342\n",
      "Epoch 142/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.2922 - acc: 0.9029 Epoch 00142: val_acc did not improve\n",
      "57/57 [==============================] - 652s 11s/step - loss: 0.2948 - acc: 0.9028 - val_loss: 0.2174 - val_acc: 0.9306\n",
      "Epoch 143/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.2955 - acc: 0.8966 Epoch 00143: val_acc did not improve\n",
      "57/57 [==============================] - 653s 11s/step - loss: 0.2943 - acc: 0.8966 - val_loss: 0.2167 - val_acc: 0.9320\n",
      "Epoch 144/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.2750 - acc: 0.9063 Epoch 00144: val_acc did not improve\n",
      "57/57 [==============================] - 651s 11s/step - loss: 0.2785 - acc: 0.9046 - val_loss: 0.2162 - val_acc: 0.9338\n",
      "Epoch 145/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.2998 - acc: 0.8962 Epoch 00145: val_acc did not improve\n",
      "57/57 [==============================] - 650s 11s/step - loss: 0.2996 - acc: 0.8962 - val_loss: 0.2173 - val_acc: 0.9287\n",
      "Epoch 146/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.2952 - acc: 0.9040 Epoch 00146: val_acc improved from 0.93421 to 0.93494, saving model to best_cnn2_m.h5\n",
      "57/57 [==============================] - 651s 11s/step - loss: 0.2939 - acc: 0.9046 - val_loss: 0.2140 - val_acc: 0.9349\n",
      "Epoch 147/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.2914 - acc: 0.9033 Epoch 00147: val_acc improved from 0.93494 to 0.93531, saving model to best_cnn2_m.h5\n",
      "57/57 [==============================] - 650s 11s/step - loss: 0.2898 - acc: 0.9039 - val_loss: 0.2129 - val_acc: 0.9353\n",
      "Epoch 148/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.2783 - acc: 0.9070 Epoch 00148: val_acc did not improve\n",
      "57/57 [==============================] - 650s 11s/step - loss: 0.2788 - acc: 0.9064 - val_loss: 0.2136 - val_acc: 0.9338\n",
      "Epoch 149/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.2693 - acc: 0.9033Epoch 00149: val_acc did not improve\n",
      "57/57 [==============================] - 650s 11s/step - loss: 0.2696 - acc: 0.9031 - val_loss: 0.2127 - val_acc: 0.9346\n",
      "Epoch 150/150\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.2966 - acc: 0.8992Epoch 00150: val_acc did not improve\n",
      "57/57 [==============================] - 650s 11s/step - loss: 0.2962 - acc: 0.8991 - val_loss: 0.2124 - val_acc: 0.9346\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fccccb96ba8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(0.001), metrics=['accuracy'])\n",
    "model_p = 'best_cnn2_m.h5'\n",
    "model_chk = ModelCheckpoint(filepath=model_p, monitor='val_acc', save_best_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.5,\n",
    "                              patience=3, min_lr=0.00001)\n",
    "model.fit_generator(train_gen,\n",
    "          steps_per_epoch = train_step,\n",
    "          epochs=150,\n",
    "          validation_data = valid_gen,\n",
    "          validation_steps = valid_step,\n",
    "          callbacks=[model_chk,reduce_lr]\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  9.56657469e-01   2.55366522e-05   1.38590876e-02   8.37864936e-04\n",
      "    3.37969488e-03   7.07230720e-06   6.01768716e-06   1.31101499e-03\n",
      "    1.08352059e-03   2.28328146e-02]\n",
      " [  3.62497729e-16   9.37924779e-06   7.54788789e-06   4.08824814e-11\n",
      "    7.89072874e-05   9.99583423e-01   1.86383782e-04   1.34003145e-04\n",
      "    2.45667126e-10   3.46559688e-07]\n",
      " [  1.52506053e-27   4.50045452e-11   6.66459800e-06   1.29530777e-15\n",
      "    3.20453243e-17   3.62353103e-06   2.37218134e-09   9.99989748e-01\n",
      "    7.80898600e-17   1.55445989e-09]\n",
      " [  1.50473945e-18   4.02927911e-03   2.77140799e-07   5.26122050e-03\n",
      "    2.73179691e-11   8.38490507e-07   2.76731566e-06   1.52581606e-06\n",
      "    9.90696073e-01   8.08921413e-06]\n",
      " [  0.00000000e+00   8.91116541e-03   5.22025940e-15   5.79860881e-02\n",
      "    4.34272914e-23   6.05720904e-20   4.75697362e-26   8.32157373e-01\n",
      "    9.64871737e-13   1.00945406e-01]]\n"
     ]
    }
   ],
   "source": [
    "best_model = load_model(model_p)\n",
    "test_y = []\n",
    "for img_p in test_files:\n",
    "    tmp_x = get_img(img_p,224,False)\n",
    "    tmp_y = best_model.predict(np.array([tmp_x]))[0]\n",
    "    test_y.append(tmp_y)\n",
    "\n",
    "test_y = np.array(test_y)\n",
    "print(test_y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   fname    camera\n",
      "0  img_0002a04_manip.tif  iPhone-6\n",
      "1  img_001e31c_unalt.tif  iPhone-6\n",
      "2  img_00275cf_manip.tif  iPhone-6\n",
      "3  img_0034113_unalt.tif  iPhone-6\n",
      "4  img_00344b7_unalt.tif  iPhone-6\n",
      "                   fname             camera\n",
      "0  img_0002a04_manip.tif         Sony-NEX-7\n",
      "1  img_001e31c_unalt.tif          iPhone-4s\n",
      "2  img_00275cf_manip.tif        LG-Nexus-5x\n",
      "3  img_0034113_unalt.tif  Samsung-Galaxy-S4\n",
      "4  img_00344b7_unalt.tif        LG-Nexus-5x\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "y_res = np.argmax(test_y,axis=1)\n",
    "y_res = [list_classes[i] for i in y_res]\n",
    "df = pd.read_csv('../input/sample_submission.csv')\n",
    "print(df.head())\n",
    "f_name = [p.split('/')[-1] for p in test_files]\n",
    "df['fname'] = f_name\n",
    "df['camera'] = y_res\n",
    "print(df.head())\n",
    "df.to_csv('../results/s_cnn_2_224.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
