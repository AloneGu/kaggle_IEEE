{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "train_dir = '../input/crop_train'\n",
    "test_dir = '../input/test'\n",
    "test_files = sorted(glob.glob(test_dir+'/*'))\n",
    "train_files = sorted(glob.glob(train_dir+'/*/*'))\n",
    "from keras.models import load_model\n",
    "model = load_model('best_cnn2_manip.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def done\n",
      "processing 500\n",
      "processing 1000\n",
      "processing 1500\n",
      "processing 2000\n",
      "processing 2500\n",
      "processing 3000\n",
      "processing 3500\n",
      "processing 4000\n",
      "processing 4500\n",
      "processing 5000\n",
      "processing 5500\n",
      "processing 6000\n",
      "processing 6500\n",
      "processing 7000\n",
      "processing 7500\n",
      "processing 8000\n",
      "processing 8500\n",
      "processing 9000\n",
      "processing 9500\n",
      "processing 10000\n",
      "processing 10500\n",
      "processing 11000\n",
      "processing 11500\n",
      "processing 12000\n",
      "processing 12500\n",
      "processing 13000\n",
      "processing 13500\n",
      "processing 14000\n",
      "processing 14500\n",
      "processing 15000\n",
      "processing 15500\n",
      "processing 16000\n",
      "processing 16500\n",
      "processing 17000\n",
      "processing 17500\n",
      "processing 18000\n",
      "processing 18500\n",
      "processing 19000\n",
      "processing 19500\n",
      "processing 20000\n",
      "processing 20500\n",
      "processing 21000\n",
      "processing 21500\n",
      "processing 22000\n",
      "processing 22500\n",
      "processing 23000\n",
      "processing 23500\n",
      "processing 24000\n",
      "processing 24500\n",
      "processing 25000\n",
      "processing 25500\n",
      "processing 26000\n",
      "processing 26500\n",
      "processing 27000\n",
      "processing 27500\n",
      "processing 28000\n",
      "processing 28500\n",
      "processing 29000\n",
      "processing 29500\n",
      "processing 30000\n",
      "processing 30500\n",
      "processing 31000\n",
      "processing 31500\n",
      "processing 32000\n",
      "processing 32500\n",
      "processing 33000\n",
      "processing 33500\n",
      "processing 34000\n",
      "processing 34500\n",
      "processing 35000\n",
      "processing 35500\n",
      "processing 36000\n",
      "processing 36500\n",
      "processing 37000\n",
      "processing 37500\n",
      "processing 38000\n",
      "processing 38500\n",
      "processing 39000\n",
      "processing 39500\n",
      "processing 40000\n",
      "processing 40500\n",
      "processing 41000\n",
      "processing 41500\n",
      "processing 42000\n",
      "processing 42500\n",
      "processing 43000\n",
      "processing 43500\n",
      "train_x done\n",
      "[0.0, 1.0, 0.0, 2.2053481e-16, 0.0, 0.0, 0.0, 6.1501687e-36, 0.0, 0.0, 0.0, 8.710454e-15, 0.0, 2.3752185e-07, 0.0, 0.0, 0.0, 0.99999976, 0.0, 0.0, 0.0, 1.0, 0.0, 5.1990074e-08, 0.0, 0.0, 0.0, 8.1281329e-11, 0.0, 1.2047192e-27, 9.2855309e-15, 0.47762248, 3.5185957e-10, 0.00010120384, 0.0018708799, 1.5785806e-16, 2.4946955e-18, 0.41888604, 2.4248159e-09, 0.10151935, 0.0, 3.414447e-08, 0.0, 7.8965182e-14, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import skimage\n",
    "import skimage.io\n",
    "import scipy.misc\n",
    "import imageio\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "CROP_LEN = 224\n",
    "\n",
    "\n",
    "def center_crop(im_array):\n",
    "    center_x = im_array.shape[0] // 2\n",
    "    center_y = im_array.shape[1] // 2\n",
    "    half_crop = CROP_LEN // 2\n",
    "    a = center_x - half_crop\n",
    "    b = a + CROP_LEN\n",
    "    c = center_y - half_crop\n",
    "    d = c + CROP_LEN\n",
    "    new_im_array = im_array[a:b,c:d,:]\n",
    "    return new_im_array\n",
    "    \n",
    "       \n",
    "\n",
    "def get_tta_img(img_path):\n",
    "    im_array = np.array(Image.open((img_path)), dtype=\"uint8\")\n",
    "    img_x = im_array.shape[0]\n",
    "    img_y = im_array.shape[1]\n",
    "    im_array = im_array/127.5\n",
    "    im_array = im_array - 1.0\n",
    "    \n",
    "    img_list = []\n",
    "    img_list.append(center_crop(im_array))\n",
    "    img_list.append(im_array[0:CROP_LEN,0:CROP_LEN,:])\n",
    "    img_list.append(im_array[0:CROP_LEN,img_y-CROP_LEN:img_y,:])\n",
    "    img_list.append(im_array[img_x-CROP_LEN:img_x,0:CROP_LEN,:])\n",
    "    img_list.append(im_array[img_x-CROP_LEN:img_x,img_y-CROP_LEN:img_y,:])\n",
    "    return np.array(img_list)\n",
    "print('def done')\n",
    "\n",
    "list_classes = [\n",
    " 'Sony-NEX-7',\n",
    " 'Motorola-X',\n",
    " 'HTC-1-M7',\n",
    " 'Samsung-Galaxy-Note3',\n",
    " 'Motorola-Droid-Maxx',\n",
    " 'iPhone-4s',\n",
    " 'iPhone-6',\n",
    " 'LG-Nexus-5x',\n",
    " 'Samsung-Galaxy-S4',\n",
    " 'Motorola-Nexus-6']\n",
    "\n",
    "tmp_cnt = 0\n",
    "x_data,y_data = [],[]\n",
    "for img_p in train_files:\n",
    "    tmp_cnt += 1\n",
    "    if tmp_cnt % 500 == 0:\n",
    "        print('processing',tmp_cnt)\n",
    "    \n",
    "    tta_imgs = get_tta_img(img_p)\n",
    "    if 'manip.jpg' in img_p:\n",
    "        manip_v = 1\n",
    "    else:\n",
    "        manip_v = 0\n",
    "    \n",
    "    # add x,y\n",
    "    res = list(model.predict(tta_imgs).flatten()) + [manip_v]\n",
    "    x_data.append(res)\n",
    "    tmp_y = img_p.split('/')[-2]\n",
    "    y_data.append(list_classes.index(tmp_y))\n",
    "\n",
    "print('train_x done')\n",
    "print(x_data[0])\n",
    "print(y_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 500\n",
      "processing 1000\n",
      "processing 1500\n",
      "processing 2000\n",
      "processing 2500\n",
      "test x done\n",
      "[0.0, 0.99995399, 3.3112454e-19, 4.5980923e-05, 3.0332146e-22, 0.0, 0.0, 4.9036025e-10, 1.3284185e-14, 1.521905e-24, 0.0, 0.99958867, 1.0760441e-13, 0.00041132033, 3.2627591e-35, 0.0, 3.1115014e-38, 6.6018839e-14, 3.0085818e-09, 2.5343651e-31, 0.0, 8.6912134e-13, 0.0, 1.0, 0.0, 0.0, 0.0, 3.2298872e-30, 0.0, 0.0, 0.0, 0.9925794, 3.8657103e-20, 0.0034450183, 5.5884967e-27, 1.7942333e-37, 1.298039e-30, 0.0039756047, 2.5608717e-11, 4.5244608e-19, 0.0, 0.99997747, 8.0016189e-22, 1.7030459e-06, 4.2468068e-30, 0.0, 3.02926e-38, 2.0815325e-05, 4.361639e-14, 9.2405447e-26, 1]\n"
     ]
    }
   ],
   "source": [
    "tmp_cnt = 0\n",
    "test_x_data = []\n",
    "for img_p in test_files:\n",
    "    tmp_cnt += 1\n",
    "    if tmp_cnt % 500 == 0:\n",
    "        print('processing',tmp_cnt)\n",
    "    \n",
    "    tta_imgs = get_tta_img(img_p)\n",
    "    if 'manip' in img_p:\n",
    "        manip_v = 1\n",
    "    else:\n",
    "        manip_v = 0\n",
    "    \n",
    "    # add x,y\n",
    "    res = list(model.predict(tta_imgs).flatten()) + [manip_v]\n",
    "    test_x_data.append(res)\n",
    "\n",
    "print('test x done')\n",
    "print(test_x_data[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat done\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('../features/s_cnn_feat.pkl','wb') as fout:\n",
    "    pickle.dump([x_data,y_data,test_x_data],fout)\n",
    "print('feat done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
