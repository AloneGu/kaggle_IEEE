{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Motorola-Nexus-6': [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], 'LG-Nexus-5x': [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], 'iPhone-6': [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], 'Motorola-X': [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], 'Sony-NEX-7': [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'HTC-1-M7': [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], 'Samsung-Galaxy-S4': [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], 'Samsung-Galaxy-Note3': [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], 'Motorola-Droid-Maxx': [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], 'iPhone-4s': [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import skimage\n",
    "import skimage.io\n",
    "import scipy.misc\n",
    "import imageio\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "\n",
    "list_classes = [\n",
    " 'Sony-NEX-7',\n",
    " 'Motorola-X',\n",
    " 'HTC-1-M7',\n",
    " 'Samsung-Galaxy-Note3',\n",
    " 'Motorola-Droid-Maxx',\n",
    " 'iPhone-4s',\n",
    " 'iPhone-6',\n",
    " 'LG-Nexus-5x',\n",
    " 'Samsung-Galaxy-S4',\n",
    " 'Motorola-Nexus-6']\n",
    "\n",
    "list_dict = {}\n",
    "for i in range(10):\n",
    "    key = list_classes[i]\n",
    "    v = [0,0,0,0,0,0,0,0,0,0]\n",
    "    v[i] = 1\n",
    "    list_dict[key] = v\n",
    "print(list_dict)\n",
    "\n",
    "train_dir = '../input/crop_train'\n",
    "test_dir = '../input/test'\n",
    "test_files = sorted(glob.glob(test_dir+'/*'))\n",
    "train_files = sorted(glob.glob(train_dir+'/*/*'))\n",
    "train_data_cnt = len(train_files)\n",
    "from sklearn.utils import shuffle\n",
    "train_files = shuffle(train_files,random_state=233)\n",
    "train_cnt = int(train_data_cnt * 0.8)\n",
    "valid_cnt = train_data_cnt - train_cnt\n",
    "BATCH_SIZE = 32\n",
    "CROP_LEN = 112\n",
    "\n",
    "def random_crop(im_array):\n",
    "    # crop\n",
    "    x_range = im_array.shape[0] - CROP_LEN\n",
    "    y_range = im_array.shape[1] - CROP_LEN\n",
    "    # print(x_range,y_range)\n",
    "    a = np.random.randint(x_range)\n",
    "    b = a + CROP_LEN\n",
    "    c = np.random.randint(y_range)\n",
    "    d = c + CROP_LEN\n",
    "    new_im_array = im_array[a:b,c:d,:]\n",
    "    return new_im_array\n",
    "\n",
    "def center_crop(im_array):\n",
    "    center_x = im_array.shape[0] // 2\n",
    "    center_y = im_array.shape[1] // 2\n",
    "    half_crop = CROP_LEN // 2\n",
    "    a = center_x - half_crop\n",
    "    b = a + CROP_LEN\n",
    "    c = center_y - half_crop\n",
    "    d = c + CROP_LEN\n",
    "    new_im_array = im_array[a:b,c:d,:]\n",
    "    return new_im_array\n",
    "    \n",
    "\n",
    "def get_img(img_path, train_flag = True):\n",
    "    # read img\n",
    "    im_array = np.array(Image.open((img_path)), dtype=\"uint8\")\n",
    "    \n",
    "    # train or valid\n",
    "    if train_flag is True:\n",
    "        final_img = random_crop(im_array)\n",
    "    else:\n",
    "        final_img = center_crop(im_array)\n",
    "    \n",
    "    final_img = final_img/255.0\n",
    "    return final_img\n",
    "\n",
    "# 读取测试数据中间 224\n",
    "def get_test_img(img_path):\n",
    "    # read img\n",
    "    im_array = np.array(Image.open((img_path)), dtype=\"uint8\")\n",
    "    final_img = center_crop(im_array)\n",
    "    final_img = final_img/255.0\n",
    "    return final_img\n",
    "\n",
    "def get_y(img_path):\n",
    "    n = img_path.split('/')[-2]\n",
    "    return list_dict[n]\n",
    "\n",
    "def data_gen(file_list, batch_size=BATCH_SIZE, train_flag = True):\n",
    "    curr_idx = 0\n",
    "    data_cnt = len(file_list)\n",
    "    while True:\n",
    "        if curr_idx + batch_size > data_cnt:\n",
    "            start_idx = data_cnt-batch_size\n",
    "            end_idx = data_cnt\n",
    "            curr_idx = 0\n",
    "        else:\n",
    "            start_idx = curr_idx\n",
    "            end_idx = curr_idx + batch_size\n",
    "            curr_idx += batch_size\n",
    "        curr_fl = file_list[start_idx:end_idx]\n",
    "        curr_x = [get_img(p,train_flag) for p in curr_fl]\n",
    "        curr_x = np.array(curr_x,dtype='float32')\n",
    "        curr_y = np.array([get_y(p) for p in curr_fl])\n",
    "        yield curr_x,curr_y\n",
    "\n",
    "train_gen = data_gen(train_files[:train_cnt], BATCH_SIZE, True)\n",
    "valid_gen = data_gen(train_files[train_cnt:], BATCH_SIZE, False)\n",
    "import math\n",
    "train_step = math.ceil(train_cnt*0.5/BATCH_SIZE)\n",
    "valid_step = math.ceil(valid_cnt/BATCH_SIZE)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# def model\n",
    "from keras.models import Sequential,load_model,Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Lambda, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint,ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load best_xception_crop.h5\n"
     ]
    }
   ],
   "source": [
    "model_p = 'best_xception_crop.h5'  # copy less manip xception\n",
    "\n",
    "if os.path.exists(model_p):\n",
    "    model = load_model(model_p)\n",
    "    K.set_value(model.optimizer.lr, 0.0001)\n",
    "    print('load',model_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "549/550 [============================>.] - ETA: 0s - loss: 0.5600 - acc: 0.8103Epoch 00001: val_acc improved from -inf to 0.79114, saving model to best_xception_crop.h5\n",
      "550/550 [==============================] - 333s 606ms/step - loss: 0.5606 - acc: 0.8101 - val_loss: 0.6073 - val_acc: 0.7911\n",
      "Epoch 2/40\n",
      "549/550 [============================>.] - ETA: 0s - loss: 0.5620 - acc: 0.8108Epoch 00002: val_acc did not improve\n",
      "550/550 [==============================] - 323s 587ms/step - loss: 0.5622 - acc: 0.8106 - val_loss: 0.6356 - val_acc: 0.7818\n",
      "Epoch 3/40\n",
      "549/550 [============================>.] - ETA: 0s - loss: 0.5428 - acc: 0.8139Epoch 00003: val_acc improved from 0.79114 to 0.81943, saving model to best_xception_crop.h5\n",
      "550/550 [==============================] - 324s 590ms/step - loss: 0.5428 - acc: 0.8139 - val_loss: 0.5398 - val_acc: 0.8194\n",
      "Epoch 4/40\n",
      "549/550 [============================>.] - ETA: 0s - loss: 0.5396 - acc: 0.8198Epoch 00004: val_acc did not improve\n",
      "550/550 [==============================] - 324s 589ms/step - loss: 0.5400 - acc: 0.8197 - val_loss: 0.7193 - val_acc: 0.7575\n",
      "Epoch 5/40\n",
      "549/550 [============================>.] - ETA: 0s - loss: 0.5205 - acc: 0.8231Epoch 00005: val_acc did not improve\n",
      "550/550 [==============================] - 325s 590ms/step - loss: 0.5208 - acc: 0.8231 - val_loss: 0.6103 - val_acc: 0.7972\n",
      "Epoch 6/40\n",
      "549/550 [============================>.] - ETA: 0s - loss: 0.5180 - acc: 0.8240Epoch 00006: val_acc did not improve\n",
      "550/550 [==============================] - 324s 590ms/step - loss: 0.5181 - acc: 0.8239 - val_loss: 0.5559 - val_acc: 0.8152\n",
      "Epoch 7/40\n",
      "549/550 [============================>.] - ETA: 0s - loss: 0.5153 - acc: 0.8273Epoch 00007: val_acc improved from 0.81943 to 0.82284, saving model to best_xception_crop.h5\n",
      "550/550 [==============================] - 325s 591ms/step - loss: 0.5151 - acc: 0.8274 - val_loss: 0.5168 - val_acc: 0.8228\n",
      "Epoch 8/40\n",
      "549/550 [============================>.] - ETA: 0s - loss: 0.5026 - acc: 0.8307Epoch 00008: val_acc did not improve\n",
      "550/550 [==============================] - 325s 591ms/step - loss: 0.5031 - acc: 0.8305 - val_loss: 0.6288 - val_acc: 0.7881\n",
      "Epoch 9/40\n",
      "549/550 [============================>.] - ETA: 0s - loss: 0.4943 - acc: 0.8320Epoch 00009: val_acc did not improve\n",
      "550/550 [==============================] - 325s 590ms/step - loss: 0.4944 - acc: 0.8320 - val_loss: 0.5981 - val_acc: 0.7980\n",
      "Epoch 10/40\n",
      "549/550 [============================>.] - ETA: 0s - loss: 0.4891 - acc: 0.8367Epoch 00010: val_acc did not improve\n",
      "550/550 [==============================] - 325s 591ms/step - loss: 0.4894 - acc: 0.8367 - val_loss: 0.5474 - val_acc: 0.8166\n",
      "Epoch 11/40\n",
      "549/550 [============================>.] - ETA: 0s - loss: 0.4797 - acc: 0.8380Epoch 00011: val_acc did not improve\n",
      "550/550 [==============================] - 325s 591ms/step - loss: 0.4796 - acc: 0.8380 - val_loss: 0.6639 - val_acc: 0.7800\n",
      "Epoch 12/40\n",
      "549/550 [============================>.] - ETA: 0s - loss: 0.4717 - acc: 0.8414Epoch 00012: val_acc did not improve\n",
      "550/550 [==============================] - 325s 592ms/step - loss: 0.4718 - acc: 0.8414 - val_loss: 0.5775 - val_acc: 0.8109\n",
      "Epoch 13/40\n",
      "549/550 [============================>.] - ETA: 0s - loss: 0.4588 - acc: 0.8476Epoch 00013: val_acc improved from 0.82284 to 0.84125, saving model to best_xception_crop.h5\n",
      "550/550 [==============================] - 326s 593ms/step - loss: 0.4589 - acc: 0.8475 - val_loss: 0.4626 - val_acc: 0.8413\n",
      "Epoch 14/40\n",
      "549/550 [============================>.] - ETA: 0s - loss: 0.4524 - acc: 0.8474Epoch 00014: val_acc did not improve\n",
      "550/550 [==============================] - 326s 592ms/step - loss: 0.4524 - acc: 0.8474 - val_loss: 0.5758 - val_acc: 0.8087\n",
      "Epoch 15/40\n",
      "549/550 [============================>.] - ETA: 0s - loss: 0.4541 - acc: 0.8449Epoch 00015: val_acc did not improve\n",
      "550/550 [==============================] - 325s 592ms/step - loss: 0.4547 - acc: 0.8447 - val_loss: 0.5035 - val_acc: 0.8316\n",
      "Epoch 16/40\n",
      "549/550 [============================>.] - ETA: 0s - loss: 0.4420 - acc: 0.8519Epoch 00016: val_acc did not improve\n",
      "550/550 [==============================] - 326s 592ms/step - loss: 0.4420 - acc: 0.8519 - val_loss: 0.5149 - val_acc: 0.8252\n",
      "Epoch 17/40\n",
      "549/550 [============================>.] - ETA: 0s - loss: 0.4407 - acc: 0.8494Epoch 00017: val_acc improved from 0.84125 to 0.84818, saving model to best_xception_crop.h5\n",
      "550/550 [==============================] - 326s 592ms/step - loss: 0.4405 - acc: 0.8494 - val_loss: 0.4687 - val_acc: 0.8482\n",
      "Epoch 18/40\n",
      "549/550 [============================>.] - ETA: 0s - loss: 0.4445 - acc: 0.8506Epoch 00018: val_acc did not improve\n",
      "550/550 [==============================] - 324s 590ms/step - loss: 0.4444 - acc: 0.8507 - val_loss: 0.5554 - val_acc: 0.8175\n",
      "Epoch 19/40\n",
      "549/550 [============================>.] - ETA: 0s - loss: 0.4251 - acc: 0.8547Epoch 00019: val_acc improved from 0.84818 to 0.85920, saving model to best_xception_crop.h5\n",
      "550/550 [==============================] - 326s 592ms/step - loss: 0.4252 - acc: 0.8545 - val_loss: 0.4232 - val_acc: 0.8592\n",
      "Epoch 20/40\n",
      "549/550 [============================>.] - ETA: 0s - loss: 0.4232 - acc: 0.8547Epoch 00020: val_acc did not improve\n",
      "550/550 [==============================] - 325s 590ms/step - loss: 0.4233 - acc: 0.8547 - val_loss: 0.5035 - val_acc: 0.8316\n",
      "Epoch 21/40\n",
      "549/550 [============================>.] - ETA: 0s - loss: 0.4227 - acc: 0.8590Epoch 00021: val_acc did not improve\n",
      "550/550 [==============================] - 325s 591ms/step - loss: 0.4225 - acc: 0.8591 - val_loss: 0.4380 - val_acc: 0.8553\n",
      "Epoch 22/40\n",
      "549/550 [============================>.] - ETA: 0s - loss: 0.4083 - acc: 0.8638Epoch 00022: val_acc did not improve\n",
      "550/550 [==============================] - 325s 591ms/step - loss: 0.4084 - acc: 0.8637 - val_loss: 0.5734 - val_acc: 0.8189\n",
      "Epoch 23/40\n",
      "549/550 [============================>.] - ETA: 0s - loss: 0.4144 - acc: 0.8611Epoch 00023: val_acc improved from 0.85920 to 0.86727, saving model to best_xception_crop.h5\n",
      "550/550 [==============================] - 326s 593ms/step - loss: 0.4145 - acc: 0.8611 - val_loss: 0.4070 - val_acc: 0.8673\n",
      "Epoch 24/40\n",
      "549/550 [============================>.] - ETA: 0s - loss: 0.4025 - acc: 0.8635Epoch 00024: val_acc did not improve\n",
      "550/550 [==============================] - 326s 592ms/step - loss: 0.4029 - acc: 0.8633 - val_loss: 0.4995 - val_acc: 0.8391\n",
      "Epoch 25/40\n",
      "549/550 [============================>.] - ETA: 0s - loss: 0.4003 - acc: 0.8657Epoch 00025: val_acc did not improve\n",
      "550/550 [==============================] - 326s 592ms/step - loss: 0.4003 - acc: 0.8657 - val_loss: 0.5442 - val_acc: 0.8194\n",
      "Epoch 26/40\n",
      "549/550 [============================>.] - ETA: 0s - loss: 0.3917 - acc: 0.8678Epoch 00026: val_acc did not improve\n",
      "550/550 [==============================] - 326s 592ms/step - loss: 0.3916 - acc: 0.8677 - val_loss: 0.5117 - val_acc: 0.8314\n",
      "Epoch 27/40\n",
      "549/550 [============================>.] - ETA: 0s - loss: 0.3811 - acc: 0.8720Epoch 00027: val_acc did not improve\n",
      "550/550 [==============================] - 326s 592ms/step - loss: 0.3815 - acc: 0.8719 - val_loss: 0.4127 - val_acc: 0.8606\n",
      "Epoch 28/40\n",
      "549/550 [============================>.] - ETA: 0s - loss: 0.3917 - acc: 0.8675Epoch 00028: val_acc did not improve\n",
      "550/550 [==============================] - 326s 592ms/step - loss: 0.3922 - acc: 0.8673 - val_loss: 0.5949 - val_acc: 0.8041\n",
      "Epoch 29/40\n",
      "549/550 [============================>.] - ETA: 0s - loss: 0.3908 - acc: 0.8678Epoch 00029: val_acc did not improve\n",
      "550/550 [==============================] - 326s 592ms/step - loss: 0.3908 - acc: 0.8677 - val_loss: 0.4262 - val_acc: 0.8559\n",
      "Epoch 30/40\n",
      "549/550 [============================>.] - ETA: 0s - loss: 0.3782 - acc: 0.8703Epoch 00030: val_acc did not improve\n",
      "550/550 [==============================] - 325s 592ms/step - loss: 0.3780 - acc: 0.8703 - val_loss: 0.4798 - val_acc: 0.8426\n",
      "Epoch 31/40\n",
      "549/550 [============================>.] - ETA: 0s - loss: 0.3677 - acc: 0.8740Epoch 00031: val_acc did not improve\n",
      "550/550 [==============================] - 326s 592ms/step - loss: 0.3676 - acc: 0.8741 - val_loss: 0.5021 - val_acc: 0.8332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/40\n",
      "549/550 [============================>.] - ETA: 0s - loss: 0.3679 - acc: 0.8769Epoch 00032: val_acc did not improve\n",
      "550/550 [==============================] - 322s 585ms/step - loss: 0.3678 - acc: 0.8769 - val_loss: 0.5325 - val_acc: 0.8311\n",
      "Epoch 33/40\n",
      "549/550 [============================>.] - ETA: 0s - loss: 0.3634 - acc: 0.8759Epoch 00033: val_acc did not improve\n",
      "550/550 [==============================] - 326s 592ms/step - loss: 0.3635 - acc: 0.8757 - val_loss: 0.4241 - val_acc: 0.8631\n",
      "Epoch 34/40\n",
      "549/550 [============================>.] - ETA: 0s - loss: 0.3589 - acc: 0.8802Epoch 00034: val_acc did not improve\n",
      "550/550 [==============================] - 322s 586ms/step - loss: 0.3593 - acc: 0.8801 - val_loss: 0.4337 - val_acc: 0.8577\n",
      "Epoch 35/40\n",
      "549/550 [============================>.] - ETA: 0s - loss: 0.3485 - acc: 0.8837Epoch 00035: val_acc did not improve\n",
      "550/550 [==============================] - 323s 587ms/step - loss: 0.3486 - acc: 0.8836 - val_loss: 0.5399 - val_acc: 0.8210\n",
      "Epoch 36/40\n",
      "549/550 [============================>.] - ETA: 0s - loss: 0.3469 - acc: 0.8807Epoch 00036: val_acc did not improve\n",
      "550/550 [==============================] - 323s 588ms/step - loss: 0.3469 - acc: 0.8807 - val_loss: 0.4487 - val_acc: 0.8492\n",
      "Epoch 37/40\n",
      "549/550 [============================>.] - ETA: 0s - loss: 0.3474 - acc: 0.8823Epoch 00037: val_acc did not improve\n",
      "550/550 [==============================] - 323s 587ms/step - loss: 0.3474 - acc: 0.8823 - val_loss: 0.4113 - val_acc: 0.8659\n",
      "Epoch 38/40\n",
      "549/550 [============================>.] - ETA: 0s - loss: 0.3410 - acc: 0.8846Epoch 00038: val_acc did not improve\n",
      "550/550 [==============================] - 324s 589ms/step - loss: 0.3411 - acc: 0.8845 - val_loss: 0.3979 - val_acc: 0.8661\n",
      "Epoch 39/40\n",
      "549/550 [============================>.] - ETA: 0s - loss: 0.3380 - acc: 0.8862Epoch 00039: val_acc did not improve\n",
      "550/550 [==============================] - 324s 589ms/step - loss: 0.3384 - acc: 0.8861 - val_loss: 0.4637 - val_acc: 0.8453\n",
      "Epoch 40/40\n",
      "549/550 [============================>.] - ETA: 0s - loss: 0.3326 - acc: 0.8866Epoch 00040: val_acc did not improve\n",
      "550/550 [==============================] - 326s 593ms/step - loss: 0.3328 - acc: 0.8865 - val_loss: 0.4854 - val_acc: 0.8399\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3217339198>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_chk = ModelCheckpoint(filepath=model_p, monitor='val_acc', save_best_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.5, verbose=1,\n",
    "                              patience=3, min_lr=0.00000001)\n",
    "\n",
    "model.fit_generator(train_gen,\n",
    "          steps_per_epoch = train_step,\n",
    "          epochs=40,\n",
    "          validation_data = valid_gen,\n",
    "          validation_steps = valid_step,\n",
    "          callbacks=[model_chk,reduce_lr]\n",
    "         )\n",
    "           "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
