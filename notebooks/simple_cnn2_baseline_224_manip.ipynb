{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Motorola-Nexus-6': [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], 'Motorola-Droid-Maxx': [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], 'iPhone-6': [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], 'Sony-NEX-7': [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'iPhone-4s': [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], 'LG-Nexus-5x': [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], 'Samsung-Galaxy-S4': [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], 'Motorola-X': [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], 'Samsung-Galaxy-Note3': [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], 'HTC-1-M7': [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import skimage\n",
    "import skimage.io\n",
    "import scipy.misc\n",
    "import imageio\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "\n",
    "list_classes = [\n",
    " 'Sony-NEX-7',\n",
    " 'Motorola-X',\n",
    " 'HTC-1-M7',\n",
    " 'Samsung-Galaxy-Note3',\n",
    " 'Motorola-Droid-Maxx',\n",
    " 'iPhone-4s',\n",
    " 'iPhone-6',\n",
    " 'LG-Nexus-5x',\n",
    " 'Samsung-Galaxy-S4',\n",
    " 'Motorola-Nexus-6']\n",
    "\n",
    "list_dict = {}\n",
    "for i in range(10):\n",
    "    key = list_classes[i]\n",
    "    v = [0,0,0,0,0,0,0,0,0,0]\n",
    "    v[i] = 1\n",
    "    list_dict[key] = v\n",
    "print(list_dict)\n",
    "\n",
    "train_dir = '../input/train'\n",
    "test_dir = '../input/test'\n",
    "test_files = sorted(glob.glob(test_dir+'/*'))\n",
    "train_files = sorted(glob.glob(train_dir+'/*/*'))\n",
    "train_data_cnt = len(train_files)\n",
    "BATCH_SIZE = 48\n",
    "CROP_LEN = 224\n",
    "\n",
    "def random_crop(im_array):\n",
    "    # crop\n",
    "    x_range = im_array.shape[0] - CROP_LEN\n",
    "    y_range = im_array.shape[1] - CROP_LEN\n",
    "    # print(x_range,y_range)\n",
    "    a = np.random.randint(x_range)\n",
    "    b = a + CROP_LEN\n",
    "    c = np.random.randint(y_range)\n",
    "    d = c + CROP_LEN\n",
    "    new_im_array = im_array[a:b,c:d,:]\n",
    "    return new_im_array\n",
    "\n",
    "def center_crop(im_array):\n",
    "    center_x = im_array.shape[0] // 2\n",
    "    center_y = im_array.shape[1] // 2\n",
    "    half_crop = CROP_LEN // 2\n",
    "    a = center_x - half_crop\n",
    "    b = a + CROP_LEN\n",
    "    c = center_y - half_crop\n",
    "    d = c + CROP_LEN\n",
    "    new_im_array = im_array[a:b,c:d,:]\n",
    "    return new_im_array\n",
    "    \n",
    "\n",
    "def random_manip(img,rnd):\n",
    "    if rnd == 0:\n",
    "        return img\n",
    "    \n",
    "    elif rnd == 1:\n",
    "        # gamma 0.8\n",
    "        new_img = skimage.exposure.adjust_gamma(img, gamma=0.8)\n",
    "        return new_img\n",
    "    \n",
    "    elif rnd == 2:\n",
    "        # gamma 1.2\n",
    "        new_img = skimage.exposure.adjust_gamma(img, gamma=1.2)\n",
    "        return new_img\n",
    "    \n",
    "    elif rnd == 3:\n",
    "        # jpeg 70\n",
    "        imageio.imwrite('/tmp/quality-70.jpg', img, quality=70)\n",
    "        try:\n",
    "            new_img = np.array(Image.open(('/tmp/quality-70.jpg')), dtype=\"uint8\")\n",
    "            os.remove('/tmp/quality-70.jpg')\n",
    "            return new_img\n",
    "        except:\n",
    "            return img\n",
    "    \n",
    "    elif rnd == 4:\n",
    "        # jpeg 90\n",
    "        imageio.imwrite('/tmp/quality-90.jpg', img, quality=90)\n",
    "        try:\n",
    "            new_img = np.array(Image.open(('/tmp/quality-90.jpg')), dtype=\"uint8\")\n",
    "            os.remove('/tmp/quality-90.jpg')\n",
    "            return new_img\n",
    "        except:\n",
    "            return img\n",
    "    \n",
    "    elif rnd == 5:\n",
    "        # 2x of original image\n",
    "        new_img = scipy.misc.imresize(img, 2.0, interp='bicubic')\n",
    "        return center_crop(new_img)\n",
    "    \n",
    "    elif rnd == 6:\n",
    "        new_img = scipy.misc.imresize(img, 1.5, interp='bicubic')\n",
    "        return center_crop(new_img)\n",
    "    \n",
    "    elif rnd == 7:\n",
    "        new_img = scipy.misc.imresize(img, 0.5, interp='bicubic')\n",
    "        return new_img\n",
    "    \n",
    "    elif rnd == 8:\n",
    "        new_img = scipy.misc.imresize(img, 0.8, interp='bicubic')\n",
    "        return new_img\n",
    "    \n",
    "    else:\n",
    "        return img\n",
    "\n",
    "def get_img(img_path, train_flag = True, fake_rnd = 0):\n",
    "    # read img\n",
    "    im_array = np.array(Image.open((img_path)), dtype=\"uint8\")\n",
    "    \n",
    "    # train or valid\n",
    "    if train_flag is True:\n",
    "        # manip rnd\n",
    "        manip_rnd = np.random.randint(16) # only half manip, 1 to 8 use manip\n",
    "        #manip_rnd = 5\n",
    "        #print(manip_rnd,im_array.shape)\n",
    "        if manip_rnd < 7 or manip_rnd > 8 : \n",
    "            # no zoom in， 随机切出 224\n",
    "            im_array = random_crop(im_array)\n",
    "            # manip， 随机变化，如果放大则去中间部分\n",
    "            final_img = random_manip(im_array, manip_rnd)\n",
    "          \n",
    "        else:\n",
    "            # resize zoom out， 缩小\n",
    "            im_array = random_manip(im_array, manip_rnd)\n",
    "            # random crop on larger image， 随机切出 224\n",
    "            final_img = random_crop(im_array)\n",
    "        if final_img.shape[0]!=CROP_LEN or final_img.shape[1]!=CROP_LEN:\n",
    "            print('train',manip_rnd,final_img.shape,img_path,im_array.shape)\n",
    "    else:\n",
    "        # center crop for valid data\n",
    "        # manip rnd\n",
    "        manip_rnd = fake_rnd % 16\n",
    "        if manip_rnd < 7 or manip_rnd > 8 :\n",
    "            # no zoom in， 取中间部分\n",
    "            im_array = center_crop(im_array)\n",
    "            # manip, 随机变化，如果放大则取中间部分\n",
    "            final_img = random_manip(im_array, manip_rnd)\n",
    "        else:\n",
    "            # resize zoom out, 先缩小图片\n",
    "            im_array = random_manip(im_array, manip_rnd)\n",
    "            # random crop on larger image, 取中间部分\n",
    "            final_img = center_crop(im_array)\n",
    "        if final_img.shape[0]!=CROP_LEN or final_img.shape[1]!=CROP_LEN:\n",
    "            print('valid',manip_rnd,final_img.shape,img_path,im_array.shape)\n",
    "    \n",
    "    final_img = final_img/255.0\n",
    "    return final_img\n",
    "\n",
    "# 读取测试数据中间 224\n",
    "def get_test_img(img_path):\n",
    "    # read img\n",
    "    im_array = np.array(Image.open((img_path)), dtype=\"uint8\")\n",
    "    final_img = center_crop(im_array)\n",
    "    final_img = final_img/255.0\n",
    "    return final_img\n",
    "\n",
    "def get_y(img_path):\n",
    "    n = img_path.split('/')[-2]\n",
    "    return list_dict[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48, 224, 224, 3) (48, 10)\n",
      "float32\n",
      "[[0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1]\n",
      " [1 0 0 0 0 0 0 0 0 0]]\n",
      "(48, 224, 224, 3) (48, 10)\n",
      "float32\n",
      "[[0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1]\n",
      " [1 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "def data_gen(file_list, batch_size=BATCH_SIZE, train_flag = True):\n",
    "    curr_idx = 0\n",
    "    data_cnt = len(file_list)\n",
    "    fake_rnd = 0\n",
    "    while True:\n",
    "        if curr_idx + batch_size > data_cnt:\n",
    "            start_idx = data_cnt-batch_size\n",
    "            end_idx = data_cnt\n",
    "            curr_idx = 0\n",
    "        else:\n",
    "            start_idx = curr_idx\n",
    "            end_idx = curr_idx + batch_size\n",
    "            curr_idx += batch_size\n",
    "        curr_fl = file_list[start_idx:end_idx]\n",
    "        if train_flag is True:\n",
    "            curr_x = np.array([get_img(p,train_flag) for p in curr_fl],dtype='float32')\n",
    "        else:\n",
    "            # make validation data stable\n",
    "            curr_x = []\n",
    "            for p in curr_fl:\n",
    "                tmp_img = get_img(p,train_flag,fake_rnd)\n",
    "                curr_x.append(tmp_img)\n",
    "                fake_rnd += 1\n",
    "                fake_rnd = fake_rnd % 16\n",
    "            curr_x = np.array(curr_x,dtype='float32')\n",
    "        curr_y = np.array([get_y(p) for p in curr_fl])\n",
    "        yield curr_x,curr_y\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "train_files = shuffle(train_files,random_state=42)\n",
    "\n",
    "\n",
    "train_gen = data_gen(train_files, BATCH_SIZE, True)\n",
    "valid_gen = data_gen(train_files, BATCH_SIZE, False)\n",
    "train_step = train_data_cnt//BATCH_SIZE\n",
    "valid_step = train_step\n",
    "\n",
    "# test\n",
    "for x,y in train_gen:\n",
    "    print(x.shape,y.shape)\n",
    "    print(x.dtype)\n",
    "    print(y[:3])\n",
    "    break\n",
    "    \n",
    "# test\n",
    "for x,y in valid_gen:\n",
    "    print(x.shape,y.shape)\n",
    "    print(x.dtype)\n",
    "    print(y[:3])\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# def model\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout, Flatten, Lambda, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint,ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load best_cnn2_manip.h5\n",
      "Epoch 1/60\n",
      "56/57 [============================>.] - ETA: 6s - loss: 0.7562 - acc: 0.7533 Epoch 00001: val_acc improved from -inf to 0.76462, saving model to best_cnn2_manip.h5\n",
      "57/57 [==============================] - 820s 14s/step - loss: 0.7550 - acc: 0.7537 - val_loss: 0.7407 - val_acc: 0.7646\n",
      "Epoch 2/60\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.7980 - acc: 0.7299 Epoch 00002: val_acc improved from 0.76462 to 0.76827, saving model to best_cnn2_manip.h5\n",
      "57/57 [==============================] - 744s 13s/step - loss: 0.7994 - acc: 0.7292 - val_loss: 0.7372 - val_acc: 0.7683\n",
      "Epoch 3/60\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.8324 - acc: 0.7188 Epoch 00003: val_acc improved from 0.76827 to 0.77010, saving model to best_cnn2_manip.h5\n",
      "57/57 [==============================] - 747s 13s/step - loss: 0.8320 - acc: 0.7193 - val_loss: 0.7222 - val_acc: 0.7701\n",
      "Epoch 4/60\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.7821 - acc: 0.7418 Epoch 00004: val_acc did not improve\n",
      "57/57 [==============================] - 743s 13s/step - loss: 0.7869 - acc: 0.7401 - val_loss: 0.7322 - val_acc: 0.7675\n",
      "Epoch 5/60\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.7698 - acc: 0.7511 Epoch 00005: val_acc did not improve\n",
      "57/57 [==============================] - 738s 13s/step - loss: 0.7708 - acc: 0.7507 - val_loss: 0.7485 - val_acc: 0.7610\n",
      "Epoch 6/60\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.7725 - acc: 0.7433 Epoch 00006: val_acc did not improve\n",
      "57/57 [==============================] - 743s 13s/step - loss: 0.7714 - acc: 0.7438 - val_loss: 0.7174 - val_acc: 0.7657\n",
      "Epoch 7/60\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.7756 - acc: 0.7374 Epoch 00007: val_acc improved from 0.77010 to 0.77156, saving model to best_cnn2_manip.h5\n",
      "57/57 [==============================] - 743s 13s/step - loss: 0.7805 - acc: 0.7361 - val_loss: 0.7237 - val_acc: 0.7716\n",
      "Epoch 8/60\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.7780 - acc: 0.7452 Epoch 00008: val_acc did not improve\n",
      "57/57 [==============================] - 744s 13s/step - loss: 0.7782 - acc: 0.7456 - val_loss: 0.7239 - val_acc: 0.7646\n",
      "Epoch 9/60\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.7678 - acc: 0.7359 Epoch 00009: val_acc did not improve\n",
      "57/57 [==============================] - 744s 13s/step - loss: 0.7670 - acc: 0.7368 - val_loss: 0.7329 - val_acc: 0.7639\n",
      "Epoch 10/60\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.7950 - acc: 0.7385 Epoch 00010: val_acc did not improve\n",
      "57/57 [==============================] - 743s 13s/step - loss: 0.7961 - acc: 0.7372 - val_loss: 0.7467 - val_acc: 0.7599\n",
      "Epoch 11/60\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.7852 - acc: 0.7437 Epoch 00011: val_acc did not improve\n",
      "\n",
      "Epoch 00011: reducing learning rate to 4.999999873689376e-05.\n",
      "57/57 [==============================] - 744s 13s/step - loss: 0.7843 - acc: 0.7445 - val_loss: 0.7240 - val_acc: 0.7661\n",
      "Epoch 12/60\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.7546 - acc: 0.7385 Epoch 00012: val_acc did not improve\n",
      "57/57 [==============================] - 737s 13s/step - loss: 0.7513 - acc: 0.7398 - val_loss: 0.7238 - val_acc: 0.7679\n",
      "Epoch 13/60\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.7335 - acc: 0.7541 Epoch 00013: val_acc did not improve\n",
      "57/57 [==============================] - 748s 13s/step - loss: 0.7344 - acc: 0.7558 - val_loss: 0.7251 - val_acc: 0.7654\n",
      "Epoch 14/60\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.7726 - acc: 0.7496 Epoch 00014: val_acc did not improve\n",
      "\n",
      "Epoch 00014: reducing learning rate to 2.499999936844688e-05.\n",
      "57/57 [==============================] - 748s 13s/step - loss: 0.7697 - acc: 0.7504 - val_loss: 0.7218 - val_acc: 0.7697\n",
      "Epoch 15/60\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.7694 - acc: 0.7463 Epoch 00015: val_acc improved from 0.77156 to 0.77632, saving model to best_cnn2_manip.h5\n",
      "57/57 [==============================] - 741s 13s/step - loss: 0.7687 - acc: 0.7478 - val_loss: 0.7113 - val_acc: 0.7763\n",
      "Epoch 16/60\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.7655 - acc: 0.7522 Epoch 00016: val_acc did not improve\n",
      "57/57 [==============================] - 740s 13s/step - loss: 0.7638 - acc: 0.7533 - val_loss: 0.7160 - val_acc: 0.7708\n",
      "Epoch 17/60\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.7671 - acc: 0.7459 Epoch 00017: val_acc did not improve\n",
      "57/57 [==============================] - 741s 13s/step - loss: 0.7637 - acc: 0.7463 - val_loss: 0.7039 - val_acc: 0.7749\n",
      "Epoch 18/60\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.7552 - acc: 0.7522 Epoch 00018: val_acc did not improve\n",
      "57/57 [==============================] - 736s 13s/step - loss: 0.7570 - acc: 0.7511 - val_loss: 0.7117 - val_acc: 0.7697\n",
      "Epoch 19/60\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.7504 - acc: 0.7440 Epoch 00019: val_acc did not improve\n",
      "\n",
      "Epoch 00019: reducing learning rate to 1.249999968422344e-05.\n",
      "57/57 [==============================] - 740s 13s/step - loss: 0.7487 - acc: 0.7434 - val_loss: 0.7078 - val_acc: 0.7749\n",
      "Epoch 20/60\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.7437 - acc: 0.7489 Epoch 00020: val_acc did not improve\n",
      "57/57 [==============================] - 739s 13s/step - loss: 0.7480 - acc: 0.7471 - val_loss: 0.7072 - val_acc: 0.7723\n",
      "Epoch 21/60\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.7522 - acc: 0.7504 Epoch 00021: val_acc did not improve\n",
      "57/57 [==============================] - 739s 13s/step - loss: 0.7539 - acc: 0.7496 - val_loss: 0.7026 - val_acc: 0.7763\n",
      "Epoch 22/60\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.7687 - acc: 0.7422 Epoch 00022: val_acc did not improve\n",
      "\n",
      "Epoch 00022: reducing learning rate to 1e-05.\n",
      "57/57 [==============================] - 742s 13s/step - loss: 0.7727 - acc: 0.7394 - val_loss: 0.7047 - val_acc: 0.7749\n",
      "Epoch 23/60\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.7494 - acc: 0.7522 Epoch 00023: val_acc improved from 0.77632 to 0.77705, saving model to best_cnn2_manip.h5\n",
      "57/57 [==============================] - 748s 13s/step - loss: 0.7530 - acc: 0.7518 - val_loss: 0.7003 - val_acc: 0.7770\n",
      "Epoch 24/60\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.7401 - acc: 0.7593 Epoch 00024: val_acc did not improve\n",
      "57/57 [==============================] - 731s 13s/step - loss: 0.7398 - acc: 0.7588 - val_loss: 0.7024 - val_acc: 0.7752\n",
      "Epoch 25/60\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.7217 - acc: 0.7638 Epoch 00025: val_acc improved from 0.77705 to 0.78070, saving model to best_cnn2_manip.h5\n",
      "57/57 [==============================] - 738s 13s/step - loss: 0.7256 - acc: 0.7621 - val_loss: 0.6964 - val_acc: 0.7807\n",
      "Epoch 26/60\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.7509 - acc: 0.7489 Epoch 00026: val_acc did not improve\n",
      "57/57 [==============================] - 743s 13s/step - loss: 0.7550 - acc: 0.7482 - val_loss: 0.7001 - val_acc: 0.7774\n",
      "Epoch 27/60\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.7614 - acc: 0.7541 Epoch 00027: val_acc did not improve\n",
      "57/57 [==============================] - 742s 13s/step - loss: 0.7598 - acc: 0.7548 - val_loss: 0.7041 - val_acc: 0.7752\n",
      "Epoch 28/60\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.7542 - acc: 0.7552 Epoch 00028: val_acc did not improve\n",
      "57/57 [==============================] - 740s 13s/step - loss: 0.7592 - acc: 0.7537 - val_loss: 0.7019 - val_acc: 0.7763\n",
      "Epoch 29/60\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.7072 - acc: 0.7630 Epoch 00029: val_acc did not improve\n",
      "57/57 [==============================] - 740s 13s/step - loss: 0.7095 - acc: 0.7632 - val_loss: 0.7005 - val_acc: 0.7767\n",
      "Epoch 30/60\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.7243 - acc: 0.7593 Epoch 00030: val_acc did not improve\n",
      "57/57 [==============================] - 737s 13s/step - loss: 0.7297 - acc: 0.7588 - val_loss: 0.7003 - val_acc: 0.7781\n",
      "Epoch 31/60\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.7272 - acc: 0.7671 Epoch 00031: val_acc did not improve\n",
      "57/57 [==============================] - 738s 13s/step - loss: 0.7321 - acc: 0.7668 - val_loss: 0.7024 - val_acc: 0.7763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/60\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.7122 - acc: 0.7660 Epoch 00032: val_acc did not improve\n",
      "57/57 [==============================] - 731s 13s/step - loss: 0.7158 - acc: 0.7654 - val_loss: 0.6971 - val_acc: 0.7803\n",
      "Epoch 33/60\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.7676 - acc: 0.7463 Epoch 00033: val_acc did not improve\n",
      "57/57 [==============================] - 730s 13s/step - loss: 0.7703 - acc: 0.7456 - val_loss: 0.6968 - val_acc: 0.7763\n",
      "Epoch 34/60\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.7575 - acc: 0.7478 Epoch 00034: val_acc did not improve\n",
      "57/57 [==============================] - 732s 13s/step - loss: 0.7578 - acc: 0.7474 - val_loss: 0.6980 - val_acc: 0.7749\n",
      "Epoch 35/60\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.7386 - acc: 0.7530 Epoch 00035: val_acc did not improve\n",
      "57/57 [==============================] - 734s 13s/step - loss: 0.7422 - acc: 0.7526 - val_loss: 0.7005 - val_acc: 0.7767\n",
      "Epoch 36/60\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.7638 - acc: 0.7500 Epoch 00036: val_acc did not improve\n",
      "57/57 [==============================] - 738s 13s/step - loss: 0.7606 - acc: 0.7504 - val_loss: 0.6985 - val_acc: 0.7756\n",
      "Epoch 37/60\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.7560 - acc: 0.7455 Epoch 00037: val_acc did not improve\n",
      "57/57 [==============================] - 735s 13s/step - loss: 0.7568 - acc: 0.7445 - val_loss: 0.6953 - val_acc: 0.7770\n",
      "Epoch 38/60\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.7382 - acc: 0.7489 Epoch 00038: val_acc did not improve\n",
      "57/57 [==============================] - 729s 13s/step - loss: 0.7456 - acc: 0.7482 - val_loss: 0.6965 - val_acc: 0.7770\n",
      "Epoch 39/60\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.7520 - acc: 0.7571 Epoch 00039: val_acc did not improve\n",
      "57/57 [==============================] - 733s 13s/step - loss: 0.7521 - acc: 0.7566 - val_loss: 0.6964 - val_acc: 0.7789\n",
      "Epoch 40/60\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.7485 - acc: 0.7608 Epoch 00040: val_acc did not improve\n",
      "57/57 [==============================] - 731s 13s/step - loss: 0.7493 - acc: 0.7610 - val_loss: 0.7006 - val_acc: 0.7749\n",
      "Epoch 41/60\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.7449 - acc: 0.7563 Epoch 00041: val_acc did not improve\n",
      "57/57 [==============================] - 743s 13s/step - loss: 0.7454 - acc: 0.7551 - val_loss: 0.7018 - val_acc: 0.7760\n",
      "Epoch 42/60\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.7632 - acc: 0.7481 Epoch 00042: val_acc did not improve\n",
      "57/57 [==============================] - 734s 13s/step - loss: 0.7643 - acc: 0.7482 - val_loss: 0.7005 - val_acc: 0.7781\n",
      "Epoch 43/60\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.7530 - acc: 0.7474 Epoch 00043: val_acc did not improve\n",
      "57/57 [==============================] - 733s 13s/step - loss: 0.7577 - acc: 0.7449 - val_loss: 0.7047 - val_acc: 0.7774\n",
      "Epoch 44/60\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.7518 - acc: 0.7537 Epoch 00044: val_acc did not improve\n",
      "57/57 [==============================] - 742s 13s/step - loss: 0.7487 - acc: 0.7548 - val_loss: 0.7052 - val_acc: 0.7741\n",
      "Epoch 45/60\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.7479 - acc: 0.7511 Epoch 00045: val_acc did not improve\n",
      "57/57 [==============================] - 737s 13s/step - loss: 0.7490 - acc: 0.7504 - val_loss: 0.6989 - val_acc: 0.7774\n",
      "Epoch 46/60\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.7354 - acc: 0.7641 Epoch 00046: val_acc did not improve\n",
      "57/57 [==============================] - 734s 13s/step - loss: 0.7333 - acc: 0.7639 - val_loss: 0.6959 - val_acc: 0.7803\n",
      "Epoch 47/60\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.7586 - acc: 0.7504 Epoch 00047: val_acc did not improve\n",
      "57/57 [==============================] - 744s 13s/step - loss: 0.7595 - acc: 0.7493 - val_loss: 0.6952 - val_acc: 0.7792\n",
      "Epoch 48/60\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.7236 - acc: 0.7556 Epoch 00048: val_acc did not improve\n",
      "57/57 [==============================] - 735s 13s/step - loss: 0.7228 - acc: 0.7558 - val_loss: 0.6978 - val_acc: 0.7785\n",
      "Epoch 49/60\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.7482 - acc: 0.7470 Epoch 00049: val_acc did not improve\n",
      "57/57 [==============================] - 744s 13s/step - loss: 0.7455 - acc: 0.7482 - val_loss: 0.6981 - val_acc: 0.7767\n",
      "Epoch 50/60\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.7777 - acc: 0.7437 Epoch 00050: val_acc improved from 0.78070 to 0.78289, saving model to best_cnn2_manip.h5\n",
      "57/57 [==============================] - 733s 13s/step - loss: 0.7780 - acc: 0.7431 - val_loss: 0.6928 - val_acc: 0.7829\n",
      "Epoch 51/60\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.7509 - acc: 0.7519 Epoch 00051: val_acc did not improve\n",
      "57/57 [==============================] - 743s 13s/step - loss: 0.7529 - acc: 0.7511 - val_loss: 0.6963 - val_acc: 0.7792\n",
      "Epoch 52/60\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.7420 - acc: 0.7548 Epoch 00052: val_acc did not improve\n",
      "57/57 [==============================] - 746s 13s/step - loss: 0.7421 - acc: 0.7555 - val_loss: 0.6981 - val_acc: 0.7767\n",
      "Epoch 53/60\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.7273 - acc: 0.7619 Epoch 00053: val_acc did not improve\n",
      "57/57 [==============================] - 742s 13s/step - loss: 0.7315 - acc: 0.7599 - val_loss: 0.6948 - val_acc: 0.7796\n",
      "Epoch 54/60\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.7352 - acc: 0.7563 Epoch 00054: val_acc did not improve\n",
      "57/57 [==============================] - 736s 13s/step - loss: 0.7321 - acc: 0.7577 - val_loss: 0.6970 - val_acc: 0.7785\n",
      "Epoch 55/60\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.7301 - acc: 0.7586 Epoch 00055: val_acc did not improve\n",
      "57/57 [==============================] - 735s 13s/step - loss: 0.7323 - acc: 0.7577 - val_loss: 0.7004 - val_acc: 0.7741\n",
      "Epoch 56/60\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.7756 - acc: 0.7407 Epoch 00056: val_acc did not improve\n",
      "57/57 [==============================] - 741s 13s/step - loss: 0.7755 - acc: 0.7412 - val_loss: 0.6996 - val_acc: 0.7752\n",
      "Epoch 57/60\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.7628 - acc: 0.7608 Epoch 00057: val_acc did not improve\n",
      "57/57 [==============================] - 735s 13s/step - loss: 0.7636 - acc: 0.7606 - val_loss: 0.6995 - val_acc: 0.7730\n",
      "Epoch 58/60\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.7392 - acc: 0.7552 Epoch 00058: val_acc did not improve\n",
      "57/57 [==============================] - 744s 13s/step - loss: 0.7376 - acc: 0.7544 - val_loss: 0.7006 - val_acc: 0.7745\n",
      "Epoch 59/60\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.7637 - acc: 0.7500 Epoch 00059: val_acc did not improve\n",
      "57/57 [==============================] - 746s 13s/step - loss: 0.7659 - acc: 0.7493 - val_loss: 0.6969 - val_acc: 0.7778\n",
      "Epoch 60/60\n",
      "56/57 [============================>.] - ETA: 5s - loss: 0.7474 - acc: 0.7533 Epoch 00060: val_acc did not improve\n",
      "57/57 [==============================] - 737s 13s/step - loss: 0.7469 - acc: 0.7544 - val_loss: 0.7016 - val_acc: 0.7760\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc220799390>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pre_p = 'best_cnn2_m.h5'\n",
    "model_p = 'best_cnn2_manip.h5'\n",
    "\n",
    "if os.path.exists(model_p):\n",
    "    model = load_model(model_p)\n",
    "    print('load',model_p)\n",
    "else:\n",
    "    model = load_model(model_pre_p)\n",
    "    print('load',model_pre_p)\n",
    "    \n",
    "    \n",
    "from keras import backend as K\n",
    "K.set_value(model.optimizer.lr, 0.0001)   \n",
    "#model.compile(loss='categorical_crossentropy', optimizer=Adam(0.001), metrics=['accuracy'])\n",
    "model_chk = ModelCheckpoint(filepath=model_p, monitor='val_acc', save_best_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.5, verbose=1,\n",
    "                              patience=3, min_lr=0.00001)\n",
    "model.fit_generator(train_gen,\n",
    "          steps_per_epoch = train_step,\n",
    "          epochs=60,\n",
    "          validation_data = valid_gen,\n",
    "          validation_steps = valid_step,\n",
    "          callbacks=[model_chk,reduce_lr]\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  5.69187328e-02   4.52639535e-03   5.82332686e-02   6.97711483e-03\n",
      "    2.02290285e-02   2.13532383e-03   1.52150333e-01   5.03682315e-01\n",
      "    4.35435548e-02   1.51603967e-01]\n",
      " [  8.64548110e-06   6.14697812e-03   1.18274922e-02   5.63282229e-05\n",
      "    1.47277107e-02   9.48181808e-01   7.01102708e-03   7.49591133e-03\n",
      "    2.07707672e-05   4.52332571e-03]\n",
      " [  4.61791083e-03   9.44868661e-04   1.44347087e-01   5.66885807e-04\n",
      "    1.06459893e-02   5.17810620e-02   6.02209926e-01   1.80817410e-01\n",
      "    2.64127651e-04   3.80462664e-03]\n",
      " [  1.87744362e-08   8.98274221e-03   6.91620575e-04   5.22928610e-02\n",
      "    8.60338841e-05   2.93308403e-03   1.14685821e-03   1.14818127e-03\n",
      "    9.31029260e-01   1.68934674e-03]\n",
      " [  1.39736278e-09   6.51430428e-01   1.28902670e-04   4.22121771e-02\n",
      "    1.68957224e-04   5.07450068e-07   1.38571306e-06   2.98924088e-01\n",
      "    2.86333496e-03   4.27010097e-03]]\n"
     ]
    }
   ],
   "source": [
    "best_model = load_model(model_p)\n",
    "test_y = []\n",
    "for img_p in test_files:\n",
    "    tmp_x = get_test_img(img_p)\n",
    "    tmp_y = best_model.predict(np.array([tmp_x]))[0]\n",
    "    test_y.append(tmp_y)\n",
    "\n",
    "test_y = np.array(test_y)\n",
    "print(test_y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   fname    camera\n",
      "0  img_0002a04_manip.tif  iPhone-6\n",
      "1  img_001e31c_unalt.tif  iPhone-6\n",
      "2  img_00275cf_manip.tif  iPhone-6\n",
      "3  img_0034113_unalt.tif  iPhone-6\n",
      "4  img_00344b7_unalt.tif  iPhone-6\n",
      "                   fname             camera\n",
      "0  img_0002a04_manip.tif        LG-Nexus-5x\n",
      "1  img_001e31c_unalt.tif          iPhone-4s\n",
      "2  img_00275cf_manip.tif           iPhone-6\n",
      "3  img_0034113_unalt.tif  Samsung-Galaxy-S4\n",
      "4  img_00344b7_unalt.tif         Motorola-X\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "y_res = np.argmax(test_y,axis=1)\n",
    "y_res = [list_classes[i] for i in y_res]\n",
    "df = pd.read_csv('../input/sample_submission.csv')\n",
    "print(df.head())\n",
    "f_name = [p.split('/')[-1] for p in test_files]\n",
    "df['fname'] = f_name\n",
    "df['camera'] = y_res\n",
    "print(df.head())\n",
    "df.to_csv('../results/s_cnn_2_224_manip.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 224, 224, 3)\n",
      "(5, 10)\n",
      "[ 0.06371276  0.22887008  0.39493296  0.36697608  0.14128983  0.02203164\n",
      "  0.7416271   2.30726767  0.22275431  0.51053774]\n"
     ]
    }
   ],
   "source": [
    "# TTA\n",
    "def get_tta_img(img_path):\n",
    "    im_array = np.array(Image.open((img_path)), dtype=\"uint8\")\n",
    "    im_array = im_array/255.0\n",
    "    img_list = []\n",
    "    img_list.append(center_crop(im_array))\n",
    "    img_list.append(im_array[0:CROP_LEN,0:CROP_LEN,:])\n",
    "    img_list.append(im_array[0:CROP_LEN,512-CROP_LEN:512,:])\n",
    "    img_list.append(im_array[512-CROP_LEN:512,0:CROP_LEN,:])\n",
    "    img_list.append(im_array[512-CROP_LEN:512,512-CROP_LEN:512,:])\n",
    "    return np.array(img_list)\n",
    "tta_img = get_tta_img(test_files[0])\n",
    "print(tta_img.shape)\n",
    "tta_res = best_model.predict(tta_img)\n",
    "print(tta_res.shape)\n",
    "print(np.sum(tta_res,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  6.37127608e-02   2.28870079e-01   3.94932956e-01   3.66976082e-01\n",
      "    1.41289830e-01   2.20316425e-02   7.41627097e-01   2.30726767e+00\n",
      "    2.22754315e-01   5.10537744e-01]\n",
      " [  1.56070036e-03   7.33321160e-02   2.78607279e-01   7.34847831e-03\n",
      "    1.99906573e-01   3.45597529e+00   5.40538549e-01   1.70104414e-01\n",
      "    9.33147781e-03   2.63294995e-01]\n",
      " [  6.00059554e-02   5.53922728e-02   1.82980931e+00   2.00297870e-02\n",
      "    1.28700703e-01   9.13145542e-02   1.86309981e+00   8.00103664e-01\n",
      "    1.73491519e-02   1.34195000e-01]\n",
      " [  4.24517538e-07   1.14826098e-01   5.17186942e-03   6.30446553e-01\n",
      "    9.20893915e-04   2.11770646e-02   1.34111503e-02   3.63148786e-02\n",
      "    3.88548183e+00   2.92249382e-01]\n",
      " [  3.21637731e-06   3.40924215e+00   4.36363630e-02   5.50696492e-01\n",
      "    7.41237728e-03   1.81990923e-04   1.57955597e-04   7.94780195e-01\n",
      "    1.53702229e-01   4.01868671e-02]]\n"
     ]
    }
   ],
   "source": [
    "test_y = []\n",
    "for img_p in test_files:\n",
    "    tmp_x = get_tta_img(img_p)\n",
    "    tmp_y = best_model.predict(tmp_x)\n",
    "    tmp_y = np.sum(tmp_y,axis=0)\n",
    "    test_y.append(tmp_y)\n",
    "\n",
    "test_y = np.array(test_y)\n",
    "print(test_y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   fname             camera\n",
      "0  img_0002a04_manip.tif        LG-Nexus-5x\n",
      "1  img_001e31c_unalt.tif          iPhone-4s\n",
      "2  img_00275cf_manip.tif           iPhone-6\n",
      "3  img_0034113_unalt.tif  Samsung-Galaxy-S4\n",
      "4  img_00344b7_unalt.tif         Motorola-X\n"
     ]
    }
   ],
   "source": [
    "y_res = np.argmax(test_y,axis=1)\n",
    "y_res = [list_classes[i] for i in y_res]\n",
    "df = pd.read_csv('../input/sample_submission.csv')\n",
    "f_name = [p.split('/')[-1] for p in test_files]\n",
    "df['fname'] = f_name\n",
    "df['camera'] = y_res\n",
    "print(df.head())\n",
    "df.to_csv('../results/s_cnn_2_224_manip_tta.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
