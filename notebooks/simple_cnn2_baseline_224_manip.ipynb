{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Motorola-Nexus-6': [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], 'Motorola-X': [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], 'HTC-1-M7': [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], 'Samsung-Galaxy-S4': [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], 'iPhone-4s': [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], 'Sony-NEX-7': [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'iPhone-6': [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], 'Motorola-Droid-Maxx': [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], 'Samsung-Galaxy-Note3': [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], 'LG-Nexus-5x': [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import skimage\n",
    "import skimage.io\n",
    "import scipy.misc\n",
    "import imageio\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "\n",
    "list_classes = [\n",
    " 'Sony-NEX-7',\n",
    " 'Motorola-X',\n",
    " 'HTC-1-M7',\n",
    " 'Samsung-Galaxy-Note3',\n",
    " 'Motorola-Droid-Maxx',\n",
    " 'iPhone-4s',\n",
    " 'iPhone-6',\n",
    " 'LG-Nexus-5x',\n",
    " 'Samsung-Galaxy-S4',\n",
    " 'Motorola-Nexus-6']\n",
    "\n",
    "list_dict = {}\n",
    "for i in range(10):\n",
    "    key = list_classes[i]\n",
    "    v = [0,0,0,0,0,0,0,0,0,0]\n",
    "    v[i] = 1\n",
    "    list_dict[key] = v\n",
    "print(list_dict)\n",
    "\n",
    "train_dir = '../input/train'\n",
    "test_dir = '../input/test'\n",
    "test_files = sorted(glob.glob(test_dir+'/*'))\n",
    "train_files = sorted(glob.glob(train_dir+'/*/*'))\n",
    "train_data_cnt = len(train_files)\n",
    "BATCH_SIZE = 48\n",
    "CROP_LEN = 224\n",
    "\n",
    "def random_crop(im_array):\n",
    "    # crop\n",
    "    x_range = im_array.shape[0] - CROP_LEN\n",
    "    y_range = im_array.shape[1] - CROP_LEN\n",
    "    # print(x_range,y_range)\n",
    "    a = np.random.randint(x_range)\n",
    "    b = a + CROP_LEN\n",
    "    c = np.random.randint(y_range)\n",
    "    d = c + CROP_LEN\n",
    "    new_im_array = im_array[a:b,c:d,:]\n",
    "    return new_im_array\n",
    "\n",
    "def center_crop(im_array):\n",
    "    center_x = im_array.shape[0] // 2\n",
    "    center_y = im_array.shape[1] // 2\n",
    "    half_crop = CROP_LEN // 2\n",
    "    a = center_x - half_crop\n",
    "    b = a + CROP_LEN\n",
    "    c = center_y - half_crop\n",
    "    d = c + CROP_LEN\n",
    "    new_im_array = im_array[a:b,c:d,:]\n",
    "    return new_im_array\n",
    "    \n",
    "\n",
    "def random_manip(img,rnd):\n",
    "    if rnd == 0:\n",
    "        return img\n",
    "    \n",
    "    elif rnd == 1:\n",
    "        # gamma 0.8\n",
    "        new_img = skimage.exposure.adjust_gamma(img, gamma=0.8)\n",
    "        return new_img\n",
    "    \n",
    "    elif rnd == 2:\n",
    "        # gamma 1.2\n",
    "        new_img = skimage.exposure.adjust_gamma(img, gamma=1.2)\n",
    "        return new_img\n",
    "    \n",
    "    elif rnd == 3:\n",
    "        # jpeg 70\n",
    "        imageio.imwrite('quality-70.jpg', img, quality=70)\n",
    "        return np.array(Image.open(('quality-70.jpg')), dtype=\"uint8\")\n",
    "    \n",
    "    elif rnd == 4:\n",
    "        # jpeg 90\n",
    "        imageio.imwrite('quality-90.jpg', img, quality=90)\n",
    "        return np.array(Image.open(('quality-90.jpg')), dtype=\"uint8\")\n",
    "    \n",
    "    elif rnd == 5:\n",
    "        # 2x of original image\n",
    "        new_img = scipy.misc.imresize(img, 2.0, interp='bicubic')\n",
    "        return center_crop(new_img)\n",
    "    \n",
    "    elif rnd == 6:\n",
    "        new_img = scipy.misc.imresize(img, 1.5, interp='bicubic')\n",
    "        return center_crop(new_img)\n",
    "    \n",
    "    elif rnd == 7:\n",
    "        new_img = scipy.misc.imresize(img, 0.5, interp='bicubic')\n",
    "        return new_img\n",
    "    \n",
    "    elif rnd == 8:\n",
    "        new_img = scipy.misc.imresize(img, 0.8, interp='bicubic')\n",
    "        return new_img\n",
    "    \n",
    "    else:\n",
    "        return img\n",
    "\n",
    "def get_img(img_path, train_flag = True):\n",
    "    # read img\n",
    "    im_array = np.array(Image.open((img_path)), dtype=\"uint8\")\n",
    "    \n",
    "    # train or valid\n",
    "    if train_flag is True:\n",
    "        # manip rnd\n",
    "        manip_rnd = np.random.randint(16) # only half manip, 1 to 8 use manip\n",
    "        #manip_rnd = 5\n",
    "        #print(manip_rnd,im_array.shape)\n",
    "        if manip_rnd < 7 or manip_rnd > 8 : \n",
    "            # no zoom in， 随机切出 224\n",
    "            im_array = random_crop(im_array)\n",
    "            # manip， 随机变化，如果放大则去中间部分\n",
    "            final_img = random_manip(im_array, manip_rnd)\n",
    "          \n",
    "        else:\n",
    "            # resize zoom out， 缩小\n",
    "            im_array = random_manip(im_array, manip_rnd)\n",
    "            # random crop on larger image， 随机切出 224\n",
    "            final_img = random_crop(im_array)\n",
    "        if final_img.shape[0]!=CROP_LEN or final_img.shape[1]!=CROP_LEN:\n",
    "            print('train',manip_rnd,final_img.shape,img_path,im_array.shape)\n",
    "    else:\n",
    "        # center crop for valid data\n",
    "        # manip rnd\n",
    "        manip_rnd = np.random.randint(16)\n",
    "        if manip_rnd < 7 or manip_rnd > 8 :\n",
    "            # no zoom in， 取中间部分\n",
    "            im_array = center_crop(im_array)\n",
    "            # manip, 随机变化，如果放大则取中间部分\n",
    "            final_img = random_manip(im_array, manip_rnd)\n",
    "        else:\n",
    "            # resize zoom out, 先缩小图片\n",
    "            im_array = random_manip(im_array, manip_rnd)\n",
    "            # random crop on larger image, 取中间部分\n",
    "            final_img = center_crop(im_array)\n",
    "        if final_img.shape[0]!=CROP_LEN or final_img.shape[1]!=CROP_LEN:\n",
    "            print('valid',manip_rnd,final_img.shape,img_path,im_array.shape)\n",
    "    \n",
    "    final_img = final_img/255.0\n",
    "    return final_img\n",
    "\n",
    "# 读取测试数据中间 224\n",
    "def get_test_img(img_path):\n",
    "    # read img\n",
    "    im_array = np.array(Image.open((img_path)), dtype=\"uint8\")\n",
    "    final_img = center_crop(im_array)\n",
    "    final_img = final_img/255.0\n",
    "    return final_img\n",
    "\n",
    "def get_y(img_path):\n",
    "    n = img_path.split('/')[-2]\n",
    "    return list_dict[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48, 224, 224, 3) (48, 10)\n",
      "float32\n",
      "[[0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1]\n",
      " [1 0 0 0 0 0 0 0 0 0]]\n",
      "(48, 224, 224, 3) (48, 10)\n",
      "float32\n",
      "[[0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1]\n",
      " [1 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "def data_gen(file_list, batch_size=BATCH_SIZE, train_flag = True):\n",
    "    curr_idx = 0\n",
    "    data_cnt = len(file_list)\n",
    "    while True:\n",
    "        if curr_idx + batch_size > data_cnt:\n",
    "            start_idx = data_cnt-batch_size\n",
    "            end_idx = data_cnt\n",
    "            curr_idx = 0\n",
    "        else:\n",
    "            start_idx = curr_idx\n",
    "            end_idx = curr_idx + batch_size\n",
    "            curr_idx += batch_size\n",
    "        curr_fl = file_list[start_idx:end_idx]\n",
    "        curr_x = np.array([get_img(p,train_flag) for p in curr_fl],dtype='float32')\n",
    "        curr_y = np.array([get_y(p) for p in curr_fl])\n",
    "        yield curr_x,curr_y\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "train_files = shuffle(train_files,random_state=42)\n",
    "\n",
    "\n",
    "train_gen = data_gen(train_files, BATCH_SIZE, True)\n",
    "valid_gen = data_gen(train_files, BATCH_SIZE, False)\n",
    "train_step = train_data_cnt//BATCH_SIZE\n",
    "valid_step = train_step\n",
    "\n",
    "# test\n",
    "for x,y in train_gen:\n",
    "    print(x.shape,y.shape)\n",
    "    print(x.dtype)\n",
    "    print(y[:3])\n",
    "    break\n",
    "    \n",
    "# test\n",
    "for x,y in valid_gen:\n",
    "    print(x.shape,y.shape)\n",
    "    print(x.dtype)\n",
    "    print(y[:3])\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# def model\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout, Flatten, Lambda, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint,ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load best_cnn2_manip.h5\n",
      "Epoch 1/20\n",
      "56/57 [============================>.] - ETA: 6s - loss: 1.3761 - acc: 0.5379 Epoch 00001: val_acc improved from -inf to 0.53545, saving model to best_cnn2_manip.h5\n",
      "57/57 [==============================] - 811s 14s/step - loss: 1.3752 - acc: 0.5369 - val_loss: 1.3936 - val_acc: 0.5355\n",
      "Epoch 2/20\n",
      "56/57 [============================>.] - ETA: 5s - loss: 1.4149 - acc: 0.5197 Epoch 00002: val_acc improved from 0.53545 to 0.57529, saving model to best_cnn2_manip.h5\n",
      "57/57 [==============================] - 778s 14s/step - loss: 1.4195 - acc: 0.5179 - val_loss: 1.2431 - val_acc: 0.5753\n",
      "Epoch 3/20\n",
      "56/57 [============================>.] - ETA: 5s - loss: 1.4134 - acc: 0.5193 Epoch 00003: val_acc did not improve\n",
      "57/57 [==============================] - 756s 13s/step - loss: 1.4150 - acc: 0.5183 - val_loss: 1.3622 - val_acc: 0.5384\n",
      "Epoch 4/20\n",
      "56/57 [============================>.] - ETA: 5s - loss: 1.3842 - acc: 0.5346 Epoch 00004: val_acc did not improve\n",
      "57/57 [==============================] - 757s 13s/step - loss: 1.3832 - acc: 0.5347 - val_loss: 1.3492 - val_acc: 0.5406\n",
      "Epoch 5/20\n",
      "56/57 [============================>.] - ETA: 5s - loss: 1.4363 - acc: 0.5153 Epoch 00005: val_acc improved from 0.57529 to 0.61294, saving model to best_cnn2_manip.h5\n",
      "57/57 [==============================] - 755s 13s/step - loss: 1.4344 - acc: 0.5157 - val_loss: 1.1848 - val_acc: 0.6129\n",
      "Epoch 6/20\n",
      "56/57 [============================>.] - ETA: 5s - loss: 1.3604 - acc: 0.5394 Epoch 00006: val_acc did not improve\n",
      "57/57 [==============================] - 765s 13s/step - loss: 1.3603 - acc: 0.5384 - val_loss: 1.3953 - val_acc: 0.5380\n",
      "Epoch 7/20\n",
      "56/57 [============================>.] - ETA: 5s - loss: 1.3266 - acc: 0.5469 Epoch 00007: val_acc did not improve\n",
      "57/57 [==============================] - 748s 13s/step - loss: 1.3289 - acc: 0.5457 - val_loss: 1.2481 - val_acc: 0.5830\n",
      "Epoch 8/20\n",
      "56/57 [============================>.] - ETA: 5s - loss: 1.3431 - acc: 0.5484 Epoch 00008: val_acc did not improve\n",
      "57/57 [==============================] - 758s 13s/step - loss: 1.3453 - acc: 0.5475 - val_loss: 1.2644 - val_acc: 0.5749\n",
      "Epoch 9/20\n",
      "56/57 [============================>.] - ETA: 5s - loss: 1.3716 - acc: 0.5264 "
     ]
    }
   ],
   "source": [
    "model_pre_p = 'best_cnn2_m.h5'\n",
    "model_p = 'best_cnn2_manip.h5'\n",
    "\n",
    "if os.path.exists(model_p):\n",
    "    model = load_model(model_p)\n",
    "    print('load',model_p)\n",
    "else:\n",
    "    model = load_model(model_pre_p)\n",
    "    print('load',model_pre_p)\n",
    "\n",
    "from keras import backend as K\n",
    "K.set_value(model.optimizer.lr, 0.001)   \n",
    "#model.compile(loss='categorical_crossentropy', optimizer=Adam(0.001), metrics=['accuracy'])\n",
    "model_chk = ModelCheckpoint(filepath=model_p, monitor='val_acc', save_best_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.5, verbose=1,\n",
    "                              patience=3, min_lr=0.00001)\n",
    "model.fit_generator(train_gen,\n",
    "          steps_per_epoch = train_step,\n",
    "          epochs=20,\n",
    "          validation_data = valid_gen,\n",
    "          validation_steps = valid_step,\n",
    "          callbacks=[model_chk,reduce_lr]\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = load_model(model_p)\n",
    "test_y = []\n",
    "for img_p in test_files:\n",
    "    tmp_x = get_test_img(img_p)\n",
    "    tmp_y = best_model.predict(np.array([tmp_x]))[0]\n",
    "    test_y.append(tmp_y)\n",
    "\n",
    "test_y = np.array(test_y)\n",
    "print(test_y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "y_res = np.argmax(test_y,axis=1)\n",
    "y_res = [list_classes[i] for i in y_res]\n",
    "df = pd.read_csv('../input/sample_submission.csv')\n",
    "print(df.head())\n",
    "f_name = [p.split('/')[-1] for p in test_files]\n",
    "df['fname'] = f_name\n",
    "df['camera'] = y_res\n",
    "print(df.head())\n",
    "df.to_csv('../results/s_cnn_2_224_manip.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
