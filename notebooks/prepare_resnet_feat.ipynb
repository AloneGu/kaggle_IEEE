{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "train_dir = '../input/crop_train'\n",
    "test_dir = '../input/test'\n",
    "test_files = sorted(glob.glob(test_dir+'/*'))\n",
    "train_files = sorted(glob.glob(train_dir+'/*/*'))\n",
    "from keras.models import load_model\n",
    "model = load_model('best_resnet_crop.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import skimage\n",
    "import skimage.io\n",
    "import scipy.misc\n",
    "import imageio\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "CROP_LEN = 224\n",
    "\n",
    "\n",
    "def center_crop(im_array):\n",
    "    center_x = im_array.shape[0] // 2\n",
    "    center_y = im_array.shape[1] // 2\n",
    "    half_crop = CROP_LEN // 2\n",
    "    a = center_x - half_crop\n",
    "    b = a + CROP_LEN\n",
    "    c = center_y - half_crop\n",
    "    d = c + CROP_LEN\n",
    "    new_im_array = im_array[a:b,c:d,:]\n",
    "    return new_im_array\n",
    "    \n",
    "       \n",
    "\n",
    "def get_tta_img(img_path):\n",
    "    im_array = np.array(Image.open((img_path)), dtype=\"uint8\")\n",
    "    img_x = im_array.shape[0]\n",
    "    img_y = im_array.shape[1]\n",
    "    im_array = im_array/127.5\n",
    "    im_array = im_array - 1.0\n",
    "    \n",
    "    img_list = []\n",
    "    img_list.append(center_crop(im_array))\n",
    "    img_list.append(im_array[0:CROP_LEN,0:CROP_LEN,:])\n",
    "    img_list.append(im_array[0:CROP_LEN,img_y-CROP_LEN:img_y,:])\n",
    "    img_list.append(im_array[img_x-CROP_LEN:img_x,0:CROP_LEN,:])\n",
    "    img_list.append(im_array[img_x-CROP_LEN:img_x,img_y-CROP_LEN:img_y,:])\n",
    "    return np.array(img_list)\n",
    "print('def done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.1297887e-08, 2.7600713e-06, 0.99191189, 1.2979828e-05, 5.3780569e-10, 3.1301877e-08, 8.7635432e-05, 3.3091555e-07, 0.0079825334, 1.8027506e-06, 2]\n",
      "processing 1000\n",
      "processing 2000\n",
      "processing 3000\n",
      "processing 4000\n",
      "processing 5000\n",
      "processing 6000\n",
      "processing 7000\n",
      "processing 8000\n",
      "processing 9000\n",
      "processing 10000\n",
      "processing 11000\n",
      "processing 12000\n",
      "processing 13000\n",
      "processing 14000\n",
      "processing 15000\n",
      "processing 16000\n",
      "processing 17000\n",
      "processing 18000\n",
      "processing 19000\n",
      "processing 20000\n",
      "processing 21000\n",
      "processing 22000\n",
      "processing 23000\n",
      "processing 24000\n",
      "processing 25000\n",
      "processing 26000\n",
      "processing 27000\n",
      "processing 28000\n",
      "processing 29000\n",
      "processing 30000\n",
      "processing 31000\n",
      "processing 32000\n",
      "processing 33000\n",
      "processing 34000\n",
      "processing 35000\n",
      "processing 36000\n",
      "processing 37000\n",
      "processing 38000\n",
      "processing 39000\n",
      "processing 40000\n",
      "processing 41000\n",
      "processing 42000\n",
      "processing 43000\n",
      "train_x done\n",
      "[1.1297887e-08, 2.7600713e-06, 0.99191189, 1.2979828e-05, 5.3780569e-10, 3.1301877e-08, 8.7635432e-05, 3.3091555e-07, 0.0079825334, 1.8027506e-06, 2]\n",
      "2\n",
      "processing 1000\n",
      "processing 2000\n",
      "test x done\n",
      "[3.7488946e-06, 0.0012029372, 0.015737072, 0.0024052404, 0.011235466, 6.0130969e-06, 0.0014406599, 0.96659267, 0.00095199572, 0.00042414403, 7]\n"
     ]
    }
   ],
   "source": [
    "list_classes = [\n",
    " 'Sony-NEX-7',\n",
    " 'Motorola-X',\n",
    " 'HTC-1-M7',\n",
    " 'Samsung-Galaxy-Note3',\n",
    " 'Motorola-Droid-Maxx',\n",
    " 'iPhone-4s',\n",
    " 'iPhone-6',\n",
    " 'LG-Nexus-5x',\n",
    " 'Samsung-Galaxy-S4',\n",
    " 'Motorola-Nexus-6']\n",
    "\n",
    "dict_cls = {}\n",
    "for i,k in enumerate(list_classes):\n",
    "    dict_cls[k] = i\n",
    "\n",
    "tmp_cnt = 0\n",
    "x_data,y_data = [],[]\n",
    "for img_p in train_files:\n",
    "    tmp_cnt += 1\n",
    "    if tmp_cnt % 1000 == 0:\n",
    "        print('processing',tmp_cnt)\n",
    "    \n",
    "    tta_imgs = get_tta_img(img_p)\n",
    "    preds = list(np.mean(model.predict(tta_imgs),axis=0))\n",
    "    max_idx = np.argmax(preds)\n",
    "    \n",
    "    # add x,y\n",
    "    res = preds + [max_idx]\n",
    "    if tmp_cnt == 1:\n",
    "        print(res)\n",
    "    x_data.append(res)\n",
    "    tmp_y = img_p.split('/')[-2]\n",
    "    y_data.append(dict_cls[tmp_y])\n",
    "\n",
    "print('train_x done')\n",
    "print(x_data[0])\n",
    "print(y_data[0])\n",
    "\n",
    "tmp_cnt = 0\n",
    "test_x_data = []\n",
    "for img_p in test_files:\n",
    "    tmp_cnt += 1\n",
    "    if tmp_cnt % 1000 == 0:\n",
    "        print('processing',tmp_cnt)\n",
    "    \n",
    "    tta_imgs = get_tta_img(img_p)\n",
    "    preds = list(np.mean(model.predict(tta_imgs),axis=0))\n",
    "    max_idx = np.argmax(preds)\n",
    "    \n",
    "    # add x,y\n",
    "    res = preds + [max_idx]\n",
    "    test_x_data.append(res)\n",
    "\n",
    "print('test x done')\n",
    "print(test_x_data[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat done\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('../features/resnet_feat.pkl','wb') as fout:\n",
    "    pickle.dump([x_data,y_data,test_x_data],fout)\n",
    "print('feat done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
